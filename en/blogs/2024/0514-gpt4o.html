<!DOCTYPE html><html class=no-js lang=en> <head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content="d.run (DaoCloud Runs Intelligence)，揭示一个新一代软件体系下的全新算力世界，让算力更自由。" name=description><meta content=d.run name=author><link href=https://docs.d.run/en/blogs/2024/0514-gpt4o.html rel=canonical><link href=0702-k8s-for-genai.html rel=prev><link href=0509-model-spec.html rel=next><link href=../../../images/favicon.ico rel=icon><meta content="mkdocs-1.6.1, mkdocs-material-9.5.50" name=generator><title>OpenAI GPT-4o is Completely Free - d.run 让算力更自由</title><link href=../../../assets/stylesheets/main.a40c8224.min.css rel=stylesheet><link href=../../../assets/stylesheets/palette.06af60db.min.css rel=stylesheet><link href=../../../overrides/assets/stylesheets/main.e13ced4c.min.css rel=stylesheet><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback" rel=stylesheet><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body data-md-color-accent=indigo data-md-color-primary=indigo data-md-color-scheme=default dir=ltr> <input autocomplete=off class=md-toggle data-md-toggle=drawer id=__drawer type=checkbox> <input autocomplete=off class=md-toggle data-md-toggle=search id=__search type=checkbox> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a class=md-skip href=#openai-disrupts-the-world-gpt-4o-completely-free> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> </div> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav aria-label=Header class="md-header__inner md-grid"> <a aria-label="d.run 让算力更自由" class="md-header__button md-logo" data-md-component=logo href=/ title="d.run 让算力更自由"> <img alt=logo src=../../../images/DaoCloud.png> </a> <label class="md-header__button md-icon" for=__drawer> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> d.run 让算力更自由 </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> OpenAI GPT-4o is Completely Free </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input aria-label="Switch to light mode" class=md-option data-md-color-accent=indigo data-md-color-media=(prefers-color-scheme) data-md-color-primary=indigo data-md-color-scheme=default id=__palette_0 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_1 hidden title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg> </label> <input aria-label="Switch to dark mode" class=md-option data-md-color-accent=indigo data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary=indigo data-md-color-scheme=default id=__palette_1 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_2 hidden title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> <input aria-label="Switch to system preference" class=md-option data-md-color-accent=indigo data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary=indigo data-md-color-scheme=slate id=__palette_2 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_0 hidden title="Switch to system preference"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <div class=md-header__option> <div class=md-select> <button aria-label="Select language" class="md-header__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"></path></svg> </button> <div class=md-select__inner> <ul class=md-select__list> <li class=md-select__item> <a class=md-select__link href=../../../blogs/2024/0514-gpt4o.html hreflang=zh> 中文 </a> </li> <li class=md-select__item> <a class=md-select__link href=0514-gpt4o.html hreflang=en> English </a> </li> </ul> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input aria-label=Search autocapitalize=off autocomplete=off autocorrect=off class=md-search__input data-md-component=search-query name=query placeholder=Search required spellcheck=false type=text> <label class="md-search__icon md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav aria-label=Search class=md-search__options> <a aria-label=Share class="md-search__icon md-icon" data-clipboard data-clipboard-text data-md-component=search-share href=javascript:void(0) tabindex=-1 title=Share> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg> </a> <button aria-label=Clear class="md-search__icon md-icon" tabindex=-1 title=Clear type=reset> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix tabindex=0> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a class=md-source data-md-component=source href=https://github.com/d-run/drun-docs title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </div> <div class=md-source__repository> d-run/drun-docs </div> </a> </div> </nav> <nav aria-label=Tabs class=md-tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=https://www.daocloud.io/ class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a class=md-tabs__link href=../../index.html> d.run Documentation </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a class=md-tabs__link href=../index.html> Blogs </a> </li> <li class=md-tabs__item> <a class=md-tabs__link href=../../open/index.html> Knowledge from AI Industry </a> </li> <li class=md-tabs__item> <a class=md-tabs__link href=../../contact/index.html> Contact Us </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=Navigation class="md-nav md-nav--primary md-nav--lifted" data-md-level=0> <label class=md-nav__title for=__drawer> <a aria-label="d.run 让算力更自由" class="md-nav__button md-logo" data-md-component=logo href=/ title="d.run 让算力更自由"> <img alt=logo src=../../../images/DaoCloud.png> </a> d.run 让算力更自由 </label> <div class=md-nav__source> <a class=md-source data-md-component=source href=https://github.com/d-run/drun-docs title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </div> <div class=md-source__repository> d-run/drun-docs </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://www.daocloud.io/ class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class=md-nav__link href=../../index.html> <span class=md-ellipsis> d.run Documentation </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input checked class="md-nav__toggle md-toggle" id=__nav_3 type=checkbox> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Blogs </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=true aria-labelledby=__nav_3_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Blogs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=../index.html> <span class=md-ellipsis> Index </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=../2025/0102-ai-trend.html> <span class=md-ellipsis> AI Trend in 2025 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=d.run.html> <span class=md-ellipsis> d.run is the Ideal Platform for Generative AI </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0702-k8s-for-genai.html> <span class=md-ellipsis> K8s and Generative AI Make a Perfect Match </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id=__toc type=checkbox> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> OpenAI GPT-4o is Completely Free </span> <span class="md-nav__icon md-icon"></span> </label> <a class="md-nav__link md-nav__link--active" href=0514-gpt4o.html> <span class=md-ellipsis> OpenAI GPT-4o is Completely Free </span> </a> <nav aria-label=导航 class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 导航 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#the-all-powerful-model-gpt-4o> <span class=md-ellipsis> The All-Powerful Model GPT-4o </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#performance-evaluation-results-for-gpt-4o> <span class=md-ellipsis> Performance Evaluation Results for GPT-4o </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#chatgpt-users-will-get-more-advanced-features-for-free> <span class=md-ellipsis> ChatGPT Users Will Get More Advanced Features for Free </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#new-desktop-app-simplifies-user-workflow> <span class=md-ellipsis> New Desktop App Simplifies User Workflow </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#altman-you-open-source-we-go-free> <span class=md-ellipsis> Altman: You Open Source, We Go Free </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=0509-model-spec.html> <span class=md-ellipsis> OpenAI LLM Specifications </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0429-ai-survey.html> <span class=md-ellipsis> 2024 Large-scale AI Infrastructure Survey </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0410-cnai-wp.html> <span class=md-ellipsis> Cloud-native Artificial Intelligence White Paper </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0408-after-kimi.html> <span class=md-ellipsis> Kimi Success and Other Domestic LLM </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0407-dbrx.html> <span class=md-ellipsis> Introduction to DBRX Open Source LLM </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0403-cp-to-profit.html> <span class=md-ellipsis> Transforms Compute into Profit </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0327-transformer.html> <span class=md-ellipsis> Who Will Replace the Transformer </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0326-compute-power.html> <span class=md-ellipsis> Financial Industry Welcomes the LLM Era </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class=md-nav__link href=../../open/index.html> <span class=md-ellipsis> Knowledge from AI Industry </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=../../contact/index.html> <span class=md-ellipsis> Contact Us </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=导航 class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 导航 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#the-all-powerful-model-gpt-4o> <span class=md-ellipsis> The All-Powerful Model GPT-4o </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#performance-evaluation-results-for-gpt-4o> <span class=md-ellipsis> Performance Evaluation Results for GPT-4o </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#chatgpt-users-will-get-more-advanced-features-for-free> <span class=md-ellipsis> ChatGPT Users Will Get More Advanced Features for Free </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#new-desktop-app-simplifies-user-workflow> <span class=md-ellipsis> New Desktop App Simplifies User Workflow </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#altman-you-open-source-we-go-free> <span class=md-ellipsis> Altman: You Open Source, We Go Free </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a class="md-content__button md-icon" href=https://github.com/d-run/drun-docs/edit/main/docs/zh/docs/en/blogs/2024/0514-gpt4o.md title=查看编辑历史> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13.5 8H12v5l4.28 2.54.72-1.21-3.5-2.08zM13 3a9 9 0 0 0-9 9H1l3.96 4.03L9 12H6a7 7 0 0 1 7-7 7 7 0 0 1 7 7 7 7 0 0 1-7 7c-1.93 0-3.68-.79-4.94-2.06l-1.42 1.42A8.9 8.9 0 0 0 13 21a9 9 0 0 0 9-9 9 9 0 0 0-9-9"></path></svg> </a> <a class="md-content__button md-icon" href=https://github.com/d-run/drun-docs/edit/main/docs/zh/docs/en/blogs/2024/0514-gpt4o.md title=edit.link.title> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg> </a> <a class="md-content__button md-icon" href=https://github.com/d-run/drun-docs/edit/main/docs/zh/docs/en/blogs/2024/0514-gpt4o.md title=查看源文件> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg> </a> <h1 id=openai-disrupts-the-world-gpt-4o-completely-free>OpenAI Disrupts the World: GPT-4o Completely Free<a class=headerlink href=#openai-disrupts-the-world-gpt-4o-completely-free title="Permanent link">¶</a></h1> <blockquote> <p>Reprinted from <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650917888&idx=1&sn=7d7cf9a41642541b5df64d0c8fb5b76a">Machine Heart</a></p> </blockquote> <p>OpenAI is disrupting the world: GPT-4o is now completely free, featuring real-time voice and video interaction that is astonishing, ushering us directly into a sci-fi era!</p> <div class="admonition note"> <p class=admonition-title>Note</p> <p>Just 17 months after the launch of ChatGPT, OpenAI has released a super AI straight out of a sci-fi movie, and it’s completely free for everyone.</p> </div> <p>It’s truly shocking!</p> <p>While various tech companies are still trying to catch up with LLMs and multimodal capabilities, incorporating features like text summarization and image editing into mobile phones, the leading OpenAI has made a bold move by launching a product that even its CEO, Sam Altman, has marveled at: it’s just like something from a movie.</p> <p><img alt=Image src=../images/gpt4o-01.png></p> <p>In the early hours of May 14, OpenAI unveiled its next-generation flagship generative model, GPT-4o, and a desktop app during its first "Spring Product Launch." They showcased a series of new capabilities. This time, technology has transformed the product form, and OpenAI has taught a lesson to tech companies worldwide through its actions.</p> <p>Today’s host is OpenAI’s Chief Technology Officer, Mira Murati, who stated that they would focus on three main points:</p> <p><img alt=Image src=../images/gpt4o-02.gif></p> <ul> <li>First, OpenAI will prioritize <strong>free access</strong> for its products to make them available to more people.</li> <li>Second, OpenAI has released <strong>a desktop version of the program and an updated UI</strong>, making it simpler and more natural to use.</li> <li>Third, following GPT-4, the new version of the LLM is called <strong>GPT-4o</strong>. What’s special about GPT-4o is that it brings GPT-4-level intelligence to everyone through a very natural interaction method, including free users.</li> </ul> <p>With this update to ChatGPT, the LLM can accept any combination of text, audio, and images as input and generate any combination of text, audio, and images as output in real-time — this is the interaction method of the future.</p> <p>Recently, ChatGPT can be used without registration, and today a desktop program has been added. OpenAI’s goal is to allow people to use it effortlessly anytime and anywhere, integrating ChatGPT into your workflow. This AI is now productivity.</p> <p><img alt=Image src=../images/gpt4o-03.gif></p> <p>GPT-4o is a new LLM aimed at the future of human-computer interaction, with understanding capabilities across text, speech, and images, responding quickly and with emotional intelligence.</p> <p>At the event, an OpenAI engineer demonstrated several main capabilities of the new model using an iPhone. The most important feature is real-time voice conversation. Mark Chen said, "This is my first live launch event, and I’m a bit nervous." ChatGPT responded, "Why don’t you take a deep breath?"</p> <p>"Okay, I’ll take a deep breath."</p> <p><img alt=Image src=../images/gpt4o-04.gif></p> <p>ChatGPT immediately replied, "That’s not good; your breathing is too loud."</p> <p>If you’ve used voice assistants like Siri before, you can see a clear difference here. First, you can interrupt the AI at any time and continue the conversation without waiting for it to finish. Second, you don’t have to wait; the model responds extremely quickly, faster than human responses. Third, the model can fully understand human emotions and express various feelings itself.</p> <p>Next comes the visual capability. Another engineer wrote an equation on paper and instead of just giving the answer, ChatGPT was asked to explain step-by-step how to solve it. It seems that it has great potential in teaching problem-solving.</p> <p><img alt=Image src=../images/gpt4o-05.gif></p> <p><em>ChatGPT said, "Whenever you’re struggling with math, I’m right here with you."</em></p> <p>Next, we tried GPT-4o’s coding abilities. With some code, the desktop version of ChatGPT was opened, and it was interacted with via voice to explain what the code does and what a particular function is for, to which ChatGPT responded fluently.</p> <p>The output of the code was a temperature curve graph, and ChatGPT was asked to respond to all questions about this graph in one sentence.</p> <p><img alt=Image src=../images/gpt4o-06.gif></p> <p>It could answer questions like which month is the hottest and whether the Y-axis is in Celsius or Fahrenheit.</p> <p>OpenAI also addressed some real-time questions from users on X/Twitter, such as real-time voice translation, where the phone could be used as a translation device back and forth between Spanish and English.</p> <p>Another question was whether ChatGPT could recognize your expressions.</p> <div class=responsive-video-container> <video controls height=600 poster=./images/video-cover01.png preload=metadata src=https://harbor-test2.cn-sh2.ufileos.com/drun/gpt4o-video01.mp4></video> </div> <p>It appears that GPT-4o is already capable of real-time video understanding.</p> <p>Next, let’s take a closer look at the bombshell that OpenAI released today.</p> <h2 id=the-all-powerful-model-gpt-4o>The All-Powerful Model GPT-4o<a class=headerlink href=#the-all-powerful-model-gpt-4o title="Permanent link">¶</a></h2> <p>First, let’s introduce GPT-4o, with "o" standing for Omnimodel.</p> <p>For the first time, OpenAI has integrated all modalities into one model, significantly enhancing the practicality of LLMs.</p> <p>OpenAI CTO Mira Murati stated that GPT-4o offers "GPT-4 level" intelligence but has improved capabilities in text, visual, and audio aspects based on GPT-4, which will be "iteratively" released in the company’s products over the coming weeks.</p> <p>"The reason for GPT-4o spans voice, text, and visual," said Murati. "We know these models are getting more complex, but we want the interaction experience to be more natural and simpler, allowing you to focus solely on collaborating with GPT without having to worry about the user interface."</p> <p>GPT-4o’s performance in English text and code matches that of GPT-4 Turbo, but its performance in non-English text has significantly improved, while the API’s speed has also increased, reducing costs by 50%. Compared to existing models, GPT-4o excels in visual and audio understanding.</p> <p>It can respond to audio input in as little as 232 milliseconds, with an average response time of 320 milliseconds, similar to humans. Before the release of GPT-4o, users who experienced ChatGPT’s voice conversation capabilities noted an average delay of 2.8 seconds (GPT-3.5) and 5.4 seconds (GPT-4).</p> <p>This voice response model consists of a pipeline made up of three independent models: a simple model transcribes audio into text, GPT-3.5 or GPT-4 receives the text and outputs text, and a third simple model converts that text back into audio. However, OpenAI found that this method meant GPT-4 would lose a lot of information, as the model could not directly observe tone, multiple speakers, or background noise, nor could it output laughter, singing, or express emotions.</p> <p>With GPT-4o, OpenAI has trained a new model end-to-end across text, visual, and audio, meaning all inputs and outputs are handled by the same neural network.</p> <p>"From a technical standpoint, OpenAI has found a way to directly map audio to audio as a primary modality and to transmit video in real-time to the transformer. These require some new research on tokenization and architecture, but overall it’s a matter of data and system optimization (most things are like this)," commented Nvidia scientist Jim Fan.</p> <p><img alt=Image src=../images/gpt4o-07.webp></p> <p>GPT-4o can perform real-time reasoning across text, audio, and video, marking a significant step toward more natural human-computer interaction (and even human-machine-machine interaction).</p> <div class=responsive-video-container> <video controls poster=./images/video-cover02.png preload=metadata src=https://harbor-test2.cn-sh2.ufileos.com/drun/gpt4o-video02.mp4></video> </div> <p>OpenAI President Greg Brockman also got in on the fun online, not only allowing two GPT-4o models to converse in real-time but also having them spontaneously create a song. Although the melody was a bit "touching," the lyrics covered aspects like the room's decor style, character clothing features, and small incidents that occurred in between.</p> <p>Moreover, GPT-4o’s capabilities in understanding and generating images far surpass any existing model, making previously impossible tasks "easy as pie."</p> <p>For example, you can ask it to help print OpenAI's logo on a coaster:</p> <p><img alt=Image src=../images/gpt4o-08.webp></p> <p>After a period of technical breakthroughs, OpenAI has likely perfected the issue of generating fonts with ChatGPT.</p> <p>At the same time, GPT-4o also possesses the ability to generate 3D visual content, capable of 3D reconstruction from six generated images:</p> <p><img alt=Image src=../images/gpt4o-09.gif></p> <p><img alt=Image src=../images/gpt4o-10.gif></p> <p>Here’s a poem, and GPT-4o can format it in a handwritten style:</p> <p><img alt=Image src=../images/gpt4o-11.webp></p> <p><img alt=Image src=../images/gpt4o-12.webp></p> <p>It can also handle more complex formatting styles:</p> <p><img alt=Image src=../images/gpt4o-13.webp></p> <p><img alt=Image src=../images/gpt4o-14.webp></p> <p>With GPT-4o, you only need to input a few sentences to get a series of continuous comic storyboards:</p> <p><img alt=Image src=../images/gpt4o-15.gif></p> <p>And the following features should surprise many designers:</p> <p><img alt=Image src=../images/gpt4o-16.webp></p> <p>This is a stylized poster evolved from two candid photos:</p> <p><img alt=Image src=../images/gpt4o-17.webp></p> <p><img alt=Image src=../images/gpt4o-18.webp></p> <p>There are also some niche features, such as "text to art font":</p> <p><img alt=Image src=../images/gpt4o-19.webp></p> <h2 id=performance-evaluation-results-for-gpt-4o>Performance Evaluation Results for GPT-4o<a class=headerlink href=#performance-evaluation-results-for-gpt-4o title="Permanent link">¶</a></h2> <p>Members of the OpenAI technical team stated on X that the mysterious model "im-also-a-good-gpt2-chatbot," which sparked widespread discussion in the LMSYS Chatbot Arena, is a version of GPT-4o.</p> <p><img alt=Image src=../images/gpt4o-21.webp></p> <p>On particularly challenging prompt sets — especially in coding: GPT-4o has shown a significant performance improvement over OpenAI’s previous best models.</p> <p>Specifically, in multiple benchmark tests, GPT-4o achieved performance at the GPT-4 Turbo level in text, reasoning, and coding intelligence, while setting new highs in multilingual, audio, and visual functionalities.</p> <p><img alt=Image src=../images/gpt4o-22.webp></p> <p><em>Reasoning Improvement: GPT-4o scored a new high of 87.2% on the 5-shot MMLU (common sense questions). (Note: Llama3 400b is still in training)</em></p> <p><img alt=Image src=../images/gpt4o-23.webp></p> <p><em>Audio ASR Performance: GPT-4o has significantly improved speech recognition performance across all languages compared to Whisper-v3, especially for under-resourced languages.</em></p> <p><img alt=Image src=../images/gpt4o-24.webp></p> <p><em>GPT-4o has achieved new state-of-the-art levels in speech translation and outperformed Whisper-v3 in MLS benchmark tests.</em></p> <p><img alt=Image src=../images/gpt4o-25.webp></p> <p><em>M3Exam benchmark tests are both a multilingual assessment benchmark and a visual assessment benchmark, consisting of standardized multiple-choice questions from various countries/regions, including graphics and charts. In all language benchmark tests, GPT-4o is stronger than GPT-4.</em></p> <p>In the future, improvements in model capabilities will enable more natural, real-time voice conversations and allow users to converse with ChatGPT via real-time video. For example, users could show ChatGPT a live sports game and ask it to explain the rules.</p> <h2 id=chatgpt-users-will-get-more-advanced-features-for-free>ChatGPT Users Will Get More Advanced Features for Free<a class=headerlink href=#chatgpt-users-will-get-more-advanced-features-for-free title="Permanent link">¶</a></h2> <p>Over 100 million people use ChatGPT each week, and OpenAI announced that the text and image features of GPT-4o will start being offered for free in ChatGPT today, with Plus users receiving up to 5 times the message limit.</p> <p><img alt=Image src=../images/gpt4o-26.webp></p> <p>Now, when opening ChatGPT, we find that GPT-4o is already available.</p> <p><img alt=Image src=../images/gpt4o-27.webp></p> <p>When using GPT-4o, free ChatGPT users can now access the following features: experience GPT-4 level intelligence; users can receive responses from the model and the web.</p> <p>Additionally, free users can also have the following options ——</p> <p>Analyze data and create charts:</p> <p><img alt=Image src=../images/gpt4o-28.gif></p> <p>Engage in conversation with captured photos:</p> <p><img alt=Image src=../images/gpt4o-29.gif></p> <p>Upload files for summarization, writing, or analysis assistance:</p> <p><img alt=Image src=../images/gpt4o-30.gif></p> <p>Discover and use GPTs and the GPT app store:</p> <p><img alt=Image src=../images/gpt4o-31.gif></p> <p>And utilize memory features to create a more helpful experience.</p> <p>However, based on usage and demand, the number of messages free users can send via GPT-4o will be limited. When this limit is reached, ChatGPT will automatically switch to GPT-3.5 so users can continue the conversation.</p> <p>Moreover, OpenAI will release a new version of the voice mode GPT-4o alpha in ChatGPT Plus over the next few weeks and will roll out more new audio and video features of GPT-4o via API to a select group of trusted partners.</p> <p>Of course, through multiple model tests and iterations, GPT-4o has some limitations across all modalities. In these imperfect areas, OpenAI has stated that it is working to improve GPT-4o.</p> <p>It’s conceivable that the opening of GPT-4o's audio mode will certainly bring various new risks. Regarding safety issues, GPT-4o has built-in safety features in its cross-modal design through techniques such as filtering training data and refining model behavior post-training. OpenAI has also created a new safety system to protect voice output.</p> <h2 id=new-desktop-app-simplifies-user-workflow>New Desktop App Simplifies User Workflow<a class=headerlink href=#new-desktop-app-simplifies-user-workflow title="Permanent link">¶</a></h2> <p>For both free and paid users, OpenAI has launched a new ChatGPT desktop application for macOS. With simple keyboard shortcuts (Option + Space), users can instantly ask ChatGPT questions, and they can also take screenshots directly within the application for discussion.</p> <p><img alt=Image src=../images/gpt4o-32.gif></p> <p>Now, users can also engage in voice conversations with ChatGPT directly from their computers. The audio and video features of GPT-4o will be rolled out in the future, and users can start voice conversations by clicking the headphone icon in the bottom right corner of the desktop application.</p> <p><img alt=Image src=../images/gpt4o-33.webp></p> <p>Starting today, OpenAI will roll out the macOS application to Plus users and will make it more widely available in the coming weeks. Additionally, a Windows version will be launched later this year.</p> <h2 id=altman-you-open-source-we-go-free>Altman: You Open Source, We Go Free<a class=headerlink href=#altman-you-open-source-we-go-free title="Permanent link">¶</a></h2> <p>After the launch, OpenAI CEO Sam Altman published a long-awaited blog post detailing his thoughts during the development of GPT-4o:</p> <p>In today’s release, I want to emphasize two things.</p> <p>First, a key part of our mission is to provide powerful AI tools for free (or at a low cost) to people. I am very proud to announce that we are offering the world’s best model for free in ChatGPT, without ads or anything similar.</p> <p>When we founded OpenAI, our initial vision was to create artificial intelligence and leverage it to generate various benefits for the world. The situation has changed now; it seems we will create artificial intelligence, and others will use it to create various amazing things, from which we all will benefit.</p> <p>Of course, we are a business and will invent many paid offerings that will help us provide free, excellent AI services to billions of people (hopefully).</p> <p>Second, the new voice and video modes are the best computational interaction interfaces I have ever used. It feels like AI from a movie, and I’m still a bit surprised that it’s real. It turns out that achieving human-level response times and expressive abilities is a huge leap.</p> <p>The original ChatGPT hinted at the possibilities of a language interface, while this new thing (the GPT-4o version) feels fundamentally different — it’s fast, intelligent, fun, natural, and helpful.</p> <p>For me, interacting with a computer has never felt very natural, and that’s the truth. And as we add (optional) personalization, access to personal information, and capabilities for AI to take actions on behalf of humans, I can genuinely see an exciting future where we can do much more with computers than before.</p> <p>Finally, a huge thank you to the team for their tremendous efforts to achieve this goal!</p> <p><img alt=Image src=../images/gpt4o-34.webp></p> <p>It’s worth mentioning that last week, Altman stated in an interview that while universal basic income may be difficult to achieve, we can realize "universal basic compute." In the future, everyone could access GPT’s computing resource for free, which could be used, resold, or donated.</p> <p>"The idea is that as AI becomes more advanced and embedded in every aspect of our lives, owning a unit of a large language model like GPT-7 may be more valuable than money; you own a part of productivity," explained Altman.</p> <p>The release of GPT-4o may be just the beginning of OpenAI’s efforts in this direction.</p> <p>Yes, this is just the beginning.</p> <p>Finally, it’s worth noting that the "Guessing May 13<sup>th</sup>’s announcement" video showcased in OpenAI's blog today almost completely overlaps with a teaser video for Google’s I/O conference tomorrow, undoubtedly a direct challenge to Google. I wonder if Google felt immense pressure after seeing OpenAI’s release today?</p> <p><img alt=Image src=../images/gpt4o-35.webp></p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button class="md-top md-icon" data-md-component=top hidden type=button> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> Back to top </button> </main> <footer class=md-footer> <nav aria-label=Footer class="md-footer__inner md-grid"> <a aria-label="Previous: K8s and Generative AI Make a Perfect Match" class="md-footer__link md-footer__link--prev" href=0702-k8s-for-genai.html> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> K8s and Generative AI Make a Perfect Match </div> </div> </a> <a aria-label="Next: OpenAI LLM Specifications" class="md-footer__link md-footer__link--next" href=0509-model-spec.html> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> OpenAI LLM Specifications </div> </div> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2016 - 2024 d.run </div> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "navigation.tabs", "navigation.prune", "navigation.sections", "navigation.tabs.sticky", "navigation.tracking", "navigation.top", "search.highlight", "search.suggest", "search.share", "toc.follow", "navigation.path", "navigation.footer"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../assets/javascripts/bundle.60a45f97.min.js></script> <script src=../../../static/stylesheets/zoom_image.js></script> <script src=../../../overrides/assets/javascripts/bundle.b97a6647.min.js></script> <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6b117ea770a78bebf27e63b402da0c4e";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script> <script type=module>
      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.2.0/+esm'
    </script> <script src="https://console.d.run/drun-copilot/chatbot-sdk.umd.js?ws=302&token=N2ZlNjFkZDItNDkyMy00Y2I1LWJlM2QtZDJlMzQ2YWM5OTE5"></script> <script>document$.subscribe(() => {
            window.update_swagger_ui_iframe_height = function (id) {
                var iFrameID = document.getElementById(id);
                if (iFrameID) {
                    full_height = (iFrameID.contentWindow.document.body.scrollHeight + 80) + "px";
                    iFrameID.height = full_height;
                    iFrameID.style.height = full_height;
                }
            }
        
            let iframe_id_list = []
            var iframes = document.getElementsByClassName("swagger-ui-iframe");
            for (var i = 0; i < iframes.length; i++) { 
                iframe_id_list.push(iframes[i].getAttribute("id"))
            }
        
            let ticking = true;
            
            document.addEventListener('scroll', function(e) {
                if (!ticking) {
                    window.requestAnimationFrame(()=> {
                        let half_vh = window.innerHeight/2;
                        for(var i = 0; i < iframe_id_list.length; i++) {
                            let element = document.getElementById(iframe_id_list[i])
                            if(element==null){
                                return
                            }
                            let diff = element.getBoundingClientRect().top
                            if(element.contentWindow.update_top_val){
                                element.contentWindow.update_top_val(half_vh - diff)
                            }
                        }
                        ticking = false;
                    });
                    ticking = true;
                }
            });
        
            const dark_scheme_name = "slate"
            
            window.scheme = document.body.getAttribute("data-md-color-scheme")
            const options = {
                attributeFilter: ['data-md-color-scheme'],
            };
            function color_scheme_callback(mutations) {
                for (let mutation of mutations) {
                    if (mutation.attributeName === "data-md-color-scheme") {
                        scheme = document.body.getAttribute("data-md-color-scheme")
                        var iframe_list = document.getElementsByClassName("swagger-ui-iframe")
                        for(var i = 0; i < iframe_list.length; i++) {
                            var ele = iframe_list.item(i);
                            if (ele) {
                                if (scheme === dark_scheme_name) {
                                    ele.contentWindow.enable_dark_mode();
                                } else {
                                    ele.contentWindow.disable_dark_mode();
                                }
                            }
                        }
                    }
                }
            }
            observer = new MutationObserver(color_scheme_callback);
            observer.observe(document.body, options);
            })</script></body> </html>