<!DOCTYPE html><html class=no-js lang=en> <head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content="d.run (DaoCloud Runs Intelligence)，揭示一个新一代软件体系下的全新算力世界，让算力更自由。" name=description><meta content=d.run name=author><link href=https://docs.d.run/en/blogs/2024/0327-transformer.html rel=canonical><link href=0403-cp-to-profit.html rel=prev><link href=0326-compute-power.html rel=next><link href=../../../images/favicon.ico rel=icon><meta content="mkdocs-1.6.1, mkdocs-material-9.5.50" name=generator><title>Who Will Replace the Transformer - d.run 让算力更自由</title><link href=../../../assets/stylesheets/main.a40c8224.min.css rel=stylesheet><link href=../../../assets/stylesheets/palette.06af60db.min.css rel=stylesheet><link href=../../../overrides/assets/stylesheets/main.e13ced4c.min.css rel=stylesheet><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback" rel=stylesheet><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body data-md-color-accent=indigo data-md-color-primary=indigo data-md-color-scheme=default dir=ltr> <input autocomplete=off class=md-toggle data-md-toggle=drawer id=__drawer type=checkbox> <input autocomplete=off class=md-toggle data-md-toggle=search id=__search type=checkbox> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a class=md-skip href=#who-will-replace-the-transformer> Skip to content </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> </div> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav aria-label=Header class="md-header__inner md-grid"> <a aria-label="d.run 让算力更自由" class="md-header__button md-logo" data-md-component=logo href=/ title="d.run 让算力更自由"> <img alt=logo src=../../../images/DaoCloud.png> </a> <label class="md-header__button md-icon" for=__drawer> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> d.run 让算力更自由 </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> Who Will Replace the Transformer </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input aria-label="Switch to light mode" class=md-option data-md-color-accent=indigo data-md-color-media=(prefers-color-scheme) data-md-color-primary=indigo data-md-color-scheme=default id=__palette_0 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_1 hidden title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg> </label> <input aria-label="Switch to dark mode" class=md-option data-md-color-accent=indigo data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary=indigo data-md-color-scheme=default id=__palette_1 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_2 hidden title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> <input aria-label="Switch to system preference" class=md-option data-md-color-accent=indigo data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary=indigo data-md-color-scheme=slate id=__palette_2 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_0 hidden title="Switch to system preference"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <div class=md-header__option> <div class=md-select> <button aria-label="Select language" class="md-header__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"></path></svg> </button> <div class=md-select__inner> <ul class=md-select__list> <li class=md-select__item> <a class=md-select__link href=../../../blogs/2024/0327-transformer.html hreflang=zh> 中文 </a> </li> <li class=md-select__item> <a class=md-select__link href=0327-transformer.html hreflang=en> English </a> </li> </ul> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input aria-label=Search autocapitalize=off autocomplete=off autocorrect=off class=md-search__input data-md-component=search-query name=query placeholder=Search required spellcheck=false type=text> <label class="md-search__icon md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav aria-label=Search class=md-search__options> <a aria-label=Share class="md-search__icon md-icon" data-clipboard data-clipboard-text data-md-component=search-share href=javascript:void(0) tabindex=-1 title=Share> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg> </a> <button aria-label=Clear class="md-search__icon md-icon" tabindex=-1 title=Clear type=reset> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix tabindex=0> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> Initializing search </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a class=md-source data-md-component=source href=https://github.com/d-run/drun-docs title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </div> <div class=md-source__repository> d-run/drun-docs </div> </a> </div> </nav> <nav aria-label=Tabs class=md-tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=https://www.daocloud.io/ class=md-tabs__link> Home </a> </li> <li class=md-tabs__item> <a class=md-tabs__link href=../../index.html> d.run Documentation </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a class=md-tabs__link href=../index.html> Blogs </a> </li> <li class=md-tabs__item> <a class=md-tabs__link href=../../open/index.html> Knowledge from AI Industry </a> </li> <li class=md-tabs__item> <a class=md-tabs__link href=../../contact/index.html> Contact Us </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=Navigation class="md-nav md-nav--primary md-nav--lifted" data-md-level=0> <label class=md-nav__title for=__drawer> <a aria-label="d.run 让算力更自由" class="md-nav__button md-logo" data-md-component=logo href=/ title="d.run 让算力更自由"> <img alt=logo src=../../../images/DaoCloud.png> </a> d.run 让算力更自由 </label> <div class=md-nav__source> <a class=md-source data-md-component=source href=https://github.com/d-run/drun-docs title="Go to repository"> <div class="md-source__icon md-icon"> <svg viewbox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </div> <div class=md-source__repository> d-run/drun-docs </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://www.daocloud.io/ class=md-nav__link> <span class=md-ellipsis> Home </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class=md-nav__link href=../../index.html> <span class=md-ellipsis> d.run Documentation </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input checked class="md-nav__toggle md-toggle" id=__nav_3 type=checkbox> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> Blogs </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=true aria-labelledby=__nav_3_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> Blogs </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=../index.html> <span class=md-ellipsis> Index </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=../2025/0102-ai-trend.html> <span class=md-ellipsis> AI Trend in 2025 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=d.run.html> <span class=md-ellipsis> d.run is the Ideal Platform for Generative AI </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0702-k8s-for-genai.html> <span class=md-ellipsis> K8s and Generative AI Make a Perfect Match </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0514-gpt4o.html> <span class=md-ellipsis> OpenAI GPT-4o is Completely Free </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0509-model-spec.html> <span class=md-ellipsis> OpenAI LLM Specifications </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0429-ai-survey.html> <span class=md-ellipsis> 2024 Large-scale AI Infrastructure Survey </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0410-cnai-wp.html> <span class=md-ellipsis> Cloud-native Artificial Intelligence White Paper </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0408-after-kimi.html> <span class=md-ellipsis> Kimi Success and Other Domestic LLM </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0407-dbrx.html> <span class=md-ellipsis> Introduction to DBRX Open Source LLM </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0403-cp-to-profit.html> <span class=md-ellipsis> Transforms Compute into Profit </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id=__toc type=checkbox> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> Who Will Replace the Transformer </span> <span class="md-nav__icon md-icon"></span> </label> <a class="md-nav__link md-nav__link--active" href=0327-transformer.html> <span class=md-ellipsis> Who Will Replace the Transformer </span> </a> <nav aria-label=导航 class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 导航 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#the-past-and-present-of-the-transformer> <span class=md-ellipsis> The Past and Present of the Transformer </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#where-is-current-research-on-non-transformer-architectures-heading> <span class=md-ellipsis> Where Is Current Research on Non-Transformer Architectures Heading? </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#can-the-transformer-be-overturned> <span class=md-ellipsis> Can the Transformer Be Overturned? </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=0326-compute-power.html> <span class=md-ellipsis> Financial Industry Welcomes the LLM Era </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class=md-nav__link href=../../open/index.html> <span class=md-ellipsis> Knowledge from AI Industry </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=../../contact/index.html> <span class=md-ellipsis> Contact Us </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=导航 class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 导航 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#the-past-and-present-of-the-transformer> <span class=md-ellipsis> The Past and Present of the Transformer </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#where-is-current-research-on-non-transformer-architectures-heading> <span class=md-ellipsis> Where Is Current Research on Non-Transformer Architectures Heading? </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#can-the-transformer-be-overturned> <span class=md-ellipsis> Can the Transformer Be Overturned? </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a class="md-content__button md-icon" href=https://github.com/d-run/drun-docs/edit/main/docs/zh/docs/en/blogs/2024/0327-transformer.md title=查看编辑历史> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13.5 8H12v5l4.28 2.54.72-1.21-3.5-2.08zM13 3a9 9 0 0 0-9 9H1l3.96 4.03L9 12H6a7 7 0 0 1 7-7 7 7 0 0 1 7 7 7 7 0 0 1-7 7c-1.93 0-3.68-.79-4.94-2.06l-1.42 1.42A8.9 8.9 0 0 0 13 21a9 9 0 0 0 9-9 9 9 0 0 0-9-9"></path></svg> </a> <a class="md-content__button md-icon" href=https://github.com/d-run/drun-docs/edit/main/docs/zh/docs/en/blogs/2024/0327-transformer.md title=edit.link.title> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg> </a> <a class="md-content__button md-icon" href=https://github.com/d-run/drun-docs/edit/main/docs/zh/docs/en/blogs/2024/0327-transformer.md title=查看源文件> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg> </a> <h1 id=who-will-replace-the-transformer>Who Will Replace the Transformer?<a class=headerlink href=#who-will-replace-the-transformer title="Permanent link">¶</a></h1> <blockquote> <p>This article is reprinted from <a href=https://mp.weixin.qq.com/s/Q8PIn0FOuXkOT1TiIOuDaA>AI Technology Review</a></p> </blockquote> <p><img alt=Image src=../images/transformer01.png></p> <p>The common challenge faced by non-Transformer models is still to prove how high their ceiling is.</p> <h2 id=the-past-and-present-of-the-transformer>The Past and Present of the Transformer<a class=headerlink href=#the-past-and-present-of-the-transformer title="Permanent link">¶</a></h2> <p>The 2017 paper "Attention Is All You Need" published by Google has become a bible for contemporary artificial intelligence, and the global AI boom can be directly traced back to the invention of the Transformer.</p> <p>Due to its ability to handle both local and long-range dependencies and its parallel training capabilities, the Transformer gradually replaced the previous RNN (Recurrent Neural Network) and CNN (Convolutional Neural Network), becoming the standard paradigm for cutting-edge research in NLP (Natural Language Processing).</p> <p>Today’s mainstream AI models and products—OpenAI's ChatGPT, Google's Bard, Anthropic's Claude, Midjourney, Sora, and domestic models like Zhipu AI's ChatGLM, Baichuan Intelligent's Baichuan model, Kimi chat, etc.—are all based on the Transformer architecture.</p> <p>The Transformer has become the undisputed gold standard of today's AI technology, and its dominant position remains unshaken.</p> <p>While the Transformer has thrived, some dissenting voices have emerged, such as: "The efficiency of the Transformer is not high"; "The ceiling of the Transformer is easily seen"; "The Transformer is good, but it cannot achieve AGI or create a world model."</p> <p>This is because the power of the Transformer is also its weakness: the inherent self-attention mechanism in the Transformer presents challenges, primarily due to its quadratic complexity. This complexity makes the architecture <strong>computationally expensive and memory-intensive</strong> when dealing with long input sequences or in resource-constrained situations.</p> <p>In simple terms, this means that as the sequence length (for example, the number of words in a paragraph or the size of an image) processed by the Transformer increases, the required computational power grows quadratically, quickly becoming enormous. Hence, there is a saying that "the Transformer is not efficient." This is also a major reason for the global shortage of computing resource triggered by the current AI boom.</p> <p>Based on the limitations of the Transformer, many non-Transformer architectures have emerged, including China's RWKV, Meta's Mega, Microsoft's RetNet, Mamba, and DeepMind's Hawk and Griffin. These models have been proposed following the dominance of the Transformer in the LLM development landscape.</p> <p>Most of them build on the original RNN foundation, aiming to improve upon the flaws and limitations of the Transformer, attempting to develop what is known as "efficient Transformers," which are architectures that resemble human thinking.</p> <p>Efficient Transformers refer to models that require less memory and incur lower computational costs during training and inference, trying to overthrow the Transformer’s hegemony.</p> <h2 id=where-is-current-research-on-non-transformer-architectures-heading>Where Is Current Research on Non-Transformer Architectures Heading?<a class=headerlink href=#where-is-current-research-on-non-transformer-architectures-heading title="Permanent link">¶</a></h2> <p>Currently, mainstream non-Transformer research is primarily focused on optimizing the attention mechanism to improve the full attention aspect and finding ways to transform this part into an RNN model to enhance inference efficiency.</p> <p>Attention is the core of the Transformer—the reason the Transformer model is so powerful is that it abandoned the previously widely used recurrent and convolutional networks in favor of a special structure—the attention mechanism—to model text.</p> <p>Attention allows the model to consider the relationships between words, regardless of how far apart they are, and to identify which words and phrases in a paragraph deserve the most attention.</p> <p>This mechanism enables the Transformer to achieve parallelization in language processing, analyzing all words in a specific text simultaneously rather than sequentially. The parallelization of the Transformer provides a more comprehensive and accurate understanding of the text being read and written, making it more computationally efficient and scalable than RNNs.</p> <p>In contrast, Recurrent Neural Networks (RNNs) face the problem of vanishing gradients, making it difficult for them to train on long sequences. Additionally, they cannot parallelize in time during the training process, limiting their scalability. Convolutional Neural Networks (CNNs) excel at capturing local patterns but lack in long-range dependencies, which are crucial for many sequence processing tasks.</p> <p>However, RNNs have the advantage that when making inferences, their complexity remains constant, so their memory and computational demands grow linearly. In contrast to the quadratic growth of memory and computational complexity of the Transformer with sequence length, RNNs have lower memory and computational demands. Therefore, many non-Transformer studies today are striving to "retain the advantages of RNNs while achieving Transformer-level performance."</p> <p><strong>Based on this goal, today’s non-Transformer technical research can be divided into two main schools:</strong></p> <p>The first school, represented by RWKV, Mamba, and S4, completely replaces attention with a recurrent structure. This approach uses fixed memory to retain previous information, but it appears that while it can remember a certain length, achieving longer lengths is challenging.</p> <p>The second school aims to transform the full attention dense structure into a sparse one, such as Meta's Mega, which no longer requires calculating every element in the attention matrix during subsequent computations, thereby improving the model's efficiency.</p> <p>Analyzing the various non-Transformer models, RWKV is the first domestically developed open-source large language model with a non-Transformer architecture, and it has now evolved to the sixth generation RWKV-6. The author of RWKV, Peng Bo, began training RWKV-2 in May 2022, starting with 100 million (100M) parameters, and later in March 2023, he trained the RWKV-4 version with 14 billion (14B) parameters.</p> <p>Peng Bo once told AI Technology Review why he wanted to create a model different from the Transformer architecture:</p> <p>"Because the world itself does not operate on the logic of Transformers; the laws of the world's operation are based on structures similar to RNNs—what happens in the next second will not be related to all your past time and information, but only to the previous second. The Transformer, which needs to recognize all tokens, is unreasonable."</p> <p>Thus, RWKV uses linear attention to approximate full attention, attempting to combine the advantages of RNNs and Transformers while avoiding the drawbacks of both, alleviating the memory bottleneck and quadratic expansion issues posed by the Transformer, achieving more effective linear scaling while providing parallel training and scalability, similar to the Transformer. In short, it emphasizes high performance, low energy consumption, and low memory usage.</p> <p>Mamba, which has been discussed frequently, has two authors: Albert Gu, an assistant professor in the Machine Learning Department at Carnegie Mellon University, and Tri Dao, Chief Scientist at Together.AI.</p> <p>In their paper, they claim that Mamba is a new SSM architecture that outperforms Transformer models of comparable size in language modeling, both in pre-training and downstream evaluation. Their Mamba-3B model can compete with Transformer models twice its size and can achieve linear scaling with increasing context length, with performance improving in practical data up to million-token length sequences and achieving a fivefold increase in inference throughput.</p> <p>A non-Transformer researcher told AI Technology Review that Mamba relies entirely on recurrent structures without using attention, so when predicting the next token, <strong>its memory size remains fixed and does not increase over time; however, its problem is that during the rolling process, the memory is very small, resulting in limited extrapolation capability.</strong></p> <p>This researcher believes that Microsoft's RetNet also follows a completely recurrent approach. RetNet introduces a multi-scale retention mechanism to replace multi-head attention, with three computation paradigms: parallel, recurrent, and block-recurrent representations.</p> <p>The paper states that the inference cost of RetNet is independent of length. For a 7B model with an 8k sequence length, RetNet's decoding speed is 8.4 times faster than Transformers with key-value caching, saving 70% of memory.</p> <p>During training, RetNet can also save 25-50% of memory compared to standard Transformers, achieving a sevenfold speedup and excelling in highly optimized FlashAttention. Additionally, RetNet's inference latency is insensitive to batch size, resulting in significant throughput.</p> <p>Meta’s Mega represents the second technical route in non-Transformer research. Mega’s approach combines recurrent structures with sparse attention matrices.</p> <p>One of the core researchers of Mega, Max, told AI Technology Review that attention has irreplaceable roles, and as long as its complexity is kept within a certain range, the desired effects can be achieved. Mega spent a long time researching how to combine recurrent structures and attention for maximum efficiency.</p> <p>Therefore, Mega still employs an attention structure, but limits attention to a fixed window size while incorporating a rolling memory form similar to Mamba, though Mega's rolling form is much simplified, resulting in faster overall computation.</p> <p>"Rolling memory" means that all efficient Transformers introduce recurrent structures into the Transformer, where the model first looks at a segment of history, remembers it, then looks at the next segment, updates memory, possibly forgetting some of the first segment's history while adding the necessary parts of the second segment to the overall history, continuously rolling forward.</p> <p>The advantage of this memory approach is that the model can maintain a fixed-length rolling memory that does not increase over time, but the problem is that for certain special tasks, at the last moment, it may not know which parts of the previous memory are useful and which are not, making it difficult to complete this rolling memory.</p> <p>Mega has been trained on the same data as LLaMA and, in a fair comparison with LLaMA2, it was found that Mega2 outperformed LLaMA2 significantly under the same data conditions. Additionally, Mega uses a 32K window size for pre-training, while Transformers with the same 32K window size are much slower than Mega2. If the window size increases further, Mega's advantages will become even more apparent. Currently, Mega2 has been trained to a size of 7B.</p> <p>DeepMind's Hawk and Griffin teams also believe that attention is essential, representing gated linear RNNs, and like Mega, they belong to a hybrid model category.</p> <p>Apart from RWKV, domestic company Rockchip Intelligence has also released a general natural language LLM with a non-attention mechanism called the Yan model. Rockchip Intelligence's CTO Liu Fanping stated that Yan has no relation to linear attention or RNNs; the LLM architecture of Yan removes the high-cost attention mechanism from the Transformer, replacing it with lower-complexity linear computations, improving modeling efficiency and training speed, thus enhancing efficiency and reducing costs.</p> <h2 id=can-the-transformer-be-overturned>Can the Transformer Be Overturned?<a class=headerlink href=#can-the-transformer-be-overturned title="Permanent link">¶</a></h2> <p>While numerous non-Transformer research proposals have emerged, from an evaluation perspective, they generally outperform Transformers of equivalent size. However, they share the common challenge and skepticism: when scaled up to the size of today’s Transformer models, can they still demonstrate strong performance and efficiency improvements?</p> <p>Among them, the largest parameter model, RWKV, has 14 billion parameters; Meta's Mega has 7 billion parameters; while GPT-3 has 175 billion parameters, and GPT-4 is rumored to have 1.8 trillion parameters, indicating that non-Transformers urgently need to train a model with hundreds of billions of parameters to prove themselves.</p> <p>RWKV, the most representative non-Transformer research, has made significant progress—it has completed seed funding of several million yuan; some companies in China are reportedly trying to use RWKV to train models; and in the past year, RWKV has seen partial implementation in both To C and To B markets.</p> <p>However, several investors have told AI Technology Review that they have struggled with whether to invest in RWKV, betting on non-Transformers. Due to significant internal disagreements—fearing that non-Transformers may not perform well—they ultimately gave up.</p> <p>Currently, based on the existing hardware computing resource foundation, it is very challenging to create LLMs on the edge with Transformers; calculations and inferences still need to be done in the cloud, and the response speed is unsatisfactory, making it difficult for end-users to accept.</p> <p>An industry insider told AI Technology Review, "On the edge, RWKV may not necessarily be the optimal solution, because with advancements in semiconductors, AI chips are evolving. In the future, the costs of hardware, computing, and energy will eventually be leveled out, and LLMs could easily run directly on the edge without needing significant changes to the underlying architecture. One day, we will reach such a critical point."</p> <p>RWKV's approach operates from the framework layer, allowing the model to compute locally after lightweighting the framework. However, one investor expressed the view that the ideal state for non-Transformers is to reach OpenAI's level before discussing lightweighting, "not for the sake of being small or localized."</p> <p>The aforementioned investor evaluated RWKV as "small but complete," achieving an overall experience that can reach 60 points compared to GPT-3.5, but it is uncertain whether it can ultimately reach GPT's 80 or 90 points. This is also a problem for non-Transformers: if the complexity of the framework is discarded, it may sacrifice the upper ceiling.</p> <p>Someone close to OpenAI told AI Technology Review that OpenAI had actually tested RWKV internally but later abandoned this route, as "its ceiling has not yet been revealed from a long-term perspective, and the possibility of achieving AGI is low."</p> <p>Proving how high their ceiling is has become a common challenge for all non-Transformer architectures.</p> <p>Some model researchers claim that the Transformer has not yet reached its ceiling for text LLMs; after all, the scaling law has not failed. The bottleneck of the Transformer may still lie in generating longer sequences, such as in the multimodal domain of video generation, which is essential for achieving AGI in the future. Thus, the context window remains a bottleneck for the Transformer.</p> <p>If, like OpenAI, one is not afraid of spending money, they could continue to push the scaling law of the Transformer. However, the issue is that for every doubling of the sequence length, the cost quadruples, and the time spent also quadruples. The quadratic growth makes the Transformer inefficient in handling long sequence problems, and resources have limits.</p> <p>It is understood that leading LLM companies in China primarily utilize Transformers. However, there are speculations about whether GPT-5 will still use the Transformer architecture, as there has been no further open-sourcing since GPT-2. But most prefer to believe that the ceiling of the Transformer is still far away. Therefore, pursuing the Transformer path to catch up with GPT-4 and GPT-5 may not be wrong. In the era of LLMs, everyone is betting.</p> <p>But whether the Transformer is the only path to achieving AGI remains uncertain. What can be confirmed is that the monopoly formed by the Transformer is hard to break, whether in terms of resources or ecosystem; current non-Transformer research cannot compete.</p> <p>It is understood that teams researching new non-Transformer architectures are either in academia or are startups like RWKV, with few large companies investing significant teams in researching new architectures. Thus, in terms of resources, the gap between non-Transformer research and Transformers is still substantial.</p> <p>Moreover, the biggest obstacle in front of them is the increasingly solid ecological moat of the Transformer.</p> <p>Now, whether in hardware, systems, or applications, everything is adapted and optimized around the Transformer, making the cost-effectiveness of developing other architectures lower, resulting in increasing difficulty in developing new architectures.</p> <p>In terms of evaluation, many evaluation tasks are designed to favor Transformer architectures, meaning that the tasks they design may only be solvable by Transformer models, while non-Transformers may find it difficult or more challenging. This design can showcase the advantages of Transformers but is not friendly to other architectures.</p> <p>MIT PhD student and flash-linear-attention project lead Yang Songlin once told AI Technology Review that one of the obstacles faced by non-Transformer research is the evaluation method—simply looking at perplexity shows that non-Transformers actually have no gap compared to Transformer models, but many practical capabilities (such as in-context copy and retrieval) still have significant differences. She believes that current non-Transformer models lack a more comprehensive evaluation method to improve the capability gap with Transformers.</p> <p>Undoubtedly, the current position of the Transformer remains unshakable; it is still the most powerful AI architecture today. However, outside the echo chamber effect, the work of developing the next generation of artificial intelligence architectures is being vigorously pursued.</p> <p>Breaking the monopoly is certainly difficult, but according to the laws of technological development, it is hard for any architecture to maintain eternal dominance. In the future, non-Transformers need to continue proving how high their ceiling is, and the Transformer architecture must do the same.</p> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button class="md-top md-icon" data-md-component=top hidden type=button> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> Back to top </button> </main> <footer class=md-footer> <nav aria-label=Footer class="md-footer__inner md-grid"> <a aria-label="Previous: Transforms Compute into Profit" class="md-footer__link md-footer__link--prev" href=0403-cp-to-profit.html> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> Previous </span> <div class=md-ellipsis> Transforms Compute into Profit </div> </div> </a> <a aria-label="Next: Financial Industry Welcomes the LLM Era" class="md-footer__link md-footer__link--next" href=0326-compute-power.html> <div class=md-footer__title> <span class=md-footer__direction> Next </span> <div class=md-ellipsis> Financial Industry Welcomes the LLM Era </div> </div> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2016 - 2024 d.run </div> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "navigation.tabs", "navigation.prune", "navigation.sections", "navigation.tabs.sticky", "navigation.tracking", "navigation.top", "search.highlight", "search.suggest", "search.share", "toc.follow", "navigation.path", "navigation.footer"], "search": "../../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script> <script src=../../../assets/javascripts/bundle.60a45f97.min.js></script> <script src=../../../static/stylesheets/zoom_image.js></script> <script src=../../../overrides/assets/javascripts/bundle.b97a6647.min.js></script> <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6b117ea770a78bebf27e63b402da0c4e";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script> <script type=module>
      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.2.0/+esm'
    </script> <script src="https://console.d.run/drun-copilot/chatbot-sdk.umd.js?ws=302&token=N2ZlNjFkZDItNDkyMy00Y2I1LWJlM2QtZDJlMzQ2YWM5OTE5"></script> <script>document$.subscribe(() => {
            window.update_swagger_ui_iframe_height = function (id) {
                var iFrameID = document.getElementById(id);
                if (iFrameID) {
                    full_height = (iFrameID.contentWindow.document.body.scrollHeight + 80) + "px";
                    iFrameID.height = full_height;
                    iFrameID.style.height = full_height;
                }
            }
        
            let iframe_id_list = []
            var iframes = document.getElementsByClassName("swagger-ui-iframe");
            for (var i = 0; i < iframes.length; i++) { 
                iframe_id_list.push(iframes[i].getAttribute("id"))
            }
        
            let ticking = true;
            
            document.addEventListener('scroll', function(e) {
                if (!ticking) {
                    window.requestAnimationFrame(()=> {
                        let half_vh = window.innerHeight/2;
                        for(var i = 0; i < iframe_id_list.length; i++) {
                            let element = document.getElementById(iframe_id_list[i])
                            if(element==null){
                                return
                            }
                            let diff = element.getBoundingClientRect().top
                            if(element.contentWindow.update_top_val){
                                element.contentWindow.update_top_val(half_vh - diff)
                            }
                        }
                        ticking = false;
                    });
                    ticking = true;
                }
            });
        
            const dark_scheme_name = "slate"
            
            window.scheme = document.body.getAttribute("data-md-color-scheme")
            const options = {
                attributeFilter: ['data-md-color-scheme'],
            };
            function color_scheme_callback(mutations) {
                for (let mutation of mutations) {
                    if (mutation.attributeName === "data-md-color-scheme") {
                        scheme = document.body.getAttribute("data-md-color-scheme")
                        var iframe_list = document.getElementsByClassName("swagger-ui-iframe")
                        for(var i = 0; i < iframe_list.length; i++) {
                            var ele = iframe_list.item(i);
                            if (ele) {
                                if (scheme === dark_scheme_name) {
                                    ele.contentWindow.enable_dark_mode();
                                } else {
                                    ele.contentWindow.disable_dark_mode();
                                }
                            }
                        }
                    }
                }
            }
            observer = new MutationObserver(color_scheme_callback);
            observer.observe(document.body, options);
            })</script></body> </html>