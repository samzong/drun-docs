<!DOCTYPE html><html class=no-js lang=zh> <head><meta charset=utf-8><meta content="width=device-width,initial-scale=1" name=viewport><meta content="d.run (DaoCloud Runs Intelligence)，揭示一个新一代软件体系下的全新算力世界，让算力更自由。" name=description><meta content=d.run name=author><link href=https://docs.d.run/blogs/2024/0407-dbrx.html rel=canonical><link href=0408-after-kimi.html rel=prev><link href=0403-cp-to-profit.html rel=next><link href=../../images/favicon.ico rel=icon><meta content="mkdocs-1.6.1, mkdocs-material-9.5.50" name=generator><title>DBRX 开源 LLM 介绍 - d.run 让算力更自由</title><link href=../../assets/stylesheets/main.a40c8224.min.css rel=stylesheet><link href=../../assets/stylesheets/palette.06af60db.min.css rel=stylesheet><link href=../../overrides/assets/stylesheets/main.e13ced4c.min.css rel=stylesheet><link crossorigin href=https://fonts.gstatic.com rel=preconnect><link href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback" rel=stylesheet><style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style><script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce(((e,_)=>(e<<5)-e+_.charCodeAt(0)),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script></head> <body data-md-color-accent=indigo data-md-color-primary=indigo data-md-color-scheme=default dir=ltr> <input autocomplete=off class=md-toggle data-md-toggle=drawer id=__drawer type=checkbox> <input autocomplete=off class=md-toggle data-md-toggle=search id=__search type=checkbox> <label class=md-overlay for=__drawer></label> <div data-md-component=skip> <a class=md-skip href=#dbrx-llm> 跳转至 </a> </div> <div data-md-component=announce> <aside class=md-banner> <div class="md-banner__inner md-grid md-typeset"> </div> </aside> </div> <header class="md-header md-header--shadow md-header--lifted" data-md-component=header> <nav aria-label=页眉 class="md-header__inner md-grid"> <a aria-label="d.run 让算力更自由" class="md-header__button md-logo" data-md-component=logo href=/ title="d.run 让算力更自由"> <img alt=logo src=../../images/DaoCloud.png> </a> <label class="md-header__button md-icon" for=__drawer> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M3 6h18v2H3zm0 5h18v2H3zm0 5h18v2H3z"></path></svg> </label> <div class=md-header__title data-md-component=header-title> <div class=md-header__ellipsis> <div class=md-header__topic> <span class=md-ellipsis> d.run 让算力更自由 </span> </div> <div class=md-header__topic data-md-component=header-topic> <span class=md-ellipsis> DBRX 开源 LLM 介绍 </span> </div> </div> </div> <form class=md-header__option data-md-component=palette> <input aria-label="Switch to light mode" class=md-option data-md-color-accent=indigo data-md-color-media=(prefers-color-scheme) data-md-color-primary=indigo data-md-color-scheme=default id=__palette_0 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_1 hidden title="Switch to light mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m14.3 16-.7-2h-3.2l-.7 2H7.8L11 7h2l3.2 9zM20 8.69V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12zm-9.15 3.96h2.3L12 9z"></path></svg> </label> <input aria-label="Switch to dark mode" class=md-option data-md-color-accent=indigo data-md-color-media="(prefers-color-scheme: light)" data-md-color-primary=indigo data-md-color-scheme=default id=__palette_1 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_2 hidden title="Switch to dark mode"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 8a4 4 0 0 0-4 4 4 4 0 0 0 4 4 4 4 0 0 0 4-4 4 4 0 0 0-4-4m0 10a6 6 0 0 1-6-6 6 6 0 0 1 6-6 6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> <input aria-label="Switch to system preference" class=md-option data-md-color-accent=indigo data-md-color-media="(prefers-color-scheme: dark)" data-md-color-primary=indigo data-md-color-scheme=slate id=__palette_2 name=__palette type=radio> <label class="md-header__button md-icon" for=__palette_0 hidden title="Switch to system preference"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M12 18c-.89 0-1.74-.2-2.5-.55C11.56 16.5 13 14.42 13 12s-1.44-4.5-3.5-5.45C10.26 6.2 11.11 6 12 6a6 6 0 0 1 6 6 6 6 0 0 1-6 6m8-9.31V4h-4.69L12 .69 8.69 4H4v4.69L.69 12 4 15.31V20h4.69L12 23.31 15.31 20H20v-4.69L23.31 12z"></path></svg> </label> </form> <script>var palette=__md_get("__palette");if(palette&&palette.color){if("(prefers-color-scheme)"===palette.color.media){var media=matchMedia("(prefers-color-scheme: light)"),input=document.querySelector(media.matches?"[data-md-color-media='(prefers-color-scheme: light)']":"[data-md-color-media='(prefers-color-scheme: dark)']");palette.color.media=input.getAttribute("data-md-color-media"),palette.color.scheme=input.getAttribute("data-md-color-scheme"),palette.color.primary=input.getAttribute("data-md-color-primary"),palette.color.accent=input.getAttribute("data-md-color-accent")}for(var[key,value]of Object.entries(palette.color))document.body.setAttribute("data-md-color-"+key,value)}</script> <div class=md-header__option> <div class=md-select> <button aria-label=选择当前语言 class="md-header__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="m12.87 15.07-2.54-2.51.03-.03A17.5 17.5 0 0 0 14.07 6H17V4h-7V2H8v2H1v2h11.17C11.5 7.92 10.44 9.75 9 11.35 8.07 10.32 7.3 9.19 6.69 8h-2c.73 1.63 1.73 3.17 2.98 4.56l-5.09 5.02L4 19l5-5 3.11 3.11zM18.5 10h-2L12 22h2l1.12-3h4.75L21 22h2zm-2.62 7 1.62-4.33L19.12 17z"></path></svg> </button> <div class=md-select__inner> <ul class=md-select__list> <li class=md-select__item> <a class=md-select__link href=0407-dbrx.html hreflang=zh> 中文 </a> </li> <li class=md-select__item> <a class=md-select__link href=../../en/blogs/2024/0407-dbrx.html hreflang=en> English </a> </li> </ul> </div> </div> </div> <label class="md-header__button md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> </label> <div class=md-search data-md-component=search role=dialog> <label class=md-search__overlay for=__search></label> <div class=md-search__inner role=search> <form class=md-search__form name=search> <input aria-label=搜索 autocapitalize=off autocomplete=off autocorrect=off class=md-search__input data-md-component=search-query name=query placeholder=搜索 required spellcheck=false type=text> <label class="md-search__icon md-icon" for=__search> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.52 6.52 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5"></path></svg> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </label> <nav aria-label=查找 class=md-search__options> <a aria-label=分享 class="md-search__icon md-icon" data-clipboard data-clipboard-text data-md-component=search-share href=javascript:void(0) tabindex=-1 title=分享> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M18 16.08c-.76 0-1.44.3-1.96.77L8.91 12.7c.05-.23.09-.46.09-.7s-.04-.47-.09-.7l7.05-4.11c.54.5 1.25.81 2.04.81a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3c0 .24.04.47.09.7L8.04 9.81C7.5 9.31 6.79 9 6 9a3 3 0 0 0-3 3 3 3 0 0 0 3 3c.79 0 1.5-.31 2.04-.81l7.12 4.15c-.05.21-.08.43-.08.66 0 1.61 1.31 2.91 2.92 2.91s2.92-1.3 2.92-2.91A2.92 2.92 0 0 0 18 16.08"></path></svg> </a> <button aria-label=清空当前内容 class="md-search__icon md-icon" tabindex=-1 title=清空当前内容 type=reset> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12z"></path></svg> </button> </nav> <div class=md-search__suggest data-md-component=search-suggest></div> </form> <div class=md-search__output> <div class=md-search__scrollwrap data-md-scrollfix tabindex=0> <div class=md-search-result data-md-component=search-result> <div class=md-search-result__meta> 正在初始化搜索引擎 </div> <ol class=md-search-result__list role=presentation></ol> </div> </div> </div> </div> </div> <div class=md-header__source> <a class=md-source data-md-component=source href=https://github.com/d-run/drun-docs title=前往仓库> <div class="md-source__icon md-icon"> <svg viewbox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </div> <div class=md-source__repository> d-run/drun-docs </div> </a> </div> </nav> <nav aria-label=标签 class=md-tabs data-md-component=tabs> <div class=md-grid> <ul class=md-tabs__list> <li class=md-tabs__item> <a href=https://www.daocloud.io/ class=md-tabs__link> 首页 </a> </li> <li class=md-tabs__item> <a class=md-tabs__link href=../../index.html> d.run 文档 </a> </li> <li class="md-tabs__item md-tabs__item--active"> <a class=md-tabs__link href=../index.html> AI 行业新闻 </a> </li> <li class=md-tabs__item> <a class=md-tabs__link href=../../open/index.html> 智海拾贝 </a> </li> <li class=md-tabs__item> <a class=md-tabs__link href=../../contact/index.html> 联系我们 </a> </li> </ul> </div> </nav> </header> <div class=md-container data-md-component=container> <main class=md-main data-md-component=main> <div class="md-main__inner md-grid"> <div class="md-sidebar md-sidebar--primary" data-md-component=sidebar data-md-type=navigation> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=导航栏 class="md-nav md-nav--primary md-nav--lifted" data-md-level=0> <label class=md-nav__title for=__drawer> <a aria-label="d.run 让算力更自由" class="md-nav__button md-logo" data-md-component=logo href=/ title="d.run 让算力更自由"> <img alt=logo src=../../images/DaoCloud.png> </a> d.run 让算力更自由 </label> <div class=md-nav__source> <a class=md-source data-md-component=source href=https://github.com/d-run/drun-docs title=前往仓库> <div class="md-source__icon md-icon"> <svg viewbox="0 0 496 512" xmlns=http://www.w3.org/2000/svg><!-- Font Awesome Free 6.7.2 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license/free (Icons: CC BY 4.0, Fonts: SIL OFL 1.1, Code: MIT License) Copyright 2024 Fonticons, Inc.--><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6m-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3m44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9M244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8M97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1m-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7m32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1m-11.4-14.7c-1.6 1-1.6 3.6 0 5.9s4.3 3.3 5.6 2.3c1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2"></path></svg> </div> <div class=md-source__repository> d-run/drun-docs </div> </a> </div> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a href=https://www.daocloud.io/ class=md-nav__link> <span class=md-ellipsis> 首页 </span> </a> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class=md-nav__link href=../../index.html> <span class=md-ellipsis> d.run 文档 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class="md-nav__item md-nav__item--active md-nav__item--section md-nav__item--nested"> <input checked class="md-nav__toggle md-toggle" id=__nav_3 type=checkbox> <label class=md-nav__link for=__nav_3 id=__nav_3_label tabindex> <span class=md-ellipsis> AI 行业新闻 </span> <span class="md-nav__icon md-icon"></span> </label> <nav aria-expanded=true aria-labelledby=__nav_3_label class=md-nav data-md-level=1> <label class=md-nav__title for=__nav_3> <span class="md-nav__icon md-icon"></span> AI 行业新闻 </label> <ul class=md-nav__list data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=../index.html> <span class=md-ellipsis> 索引 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=../2025/0102-ai-trend.html> <span class=md-ellipsis> 2025 年人工智能趋势展望 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=d.run.html> <span class=md-ellipsis> d.run 是支撑生成式 AI 的理想平台 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0702-k8s-for-genai.html> <span class=md-ellipsis> K8s 与生成式 AI 珠联璧合 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0514-gpt4o.html> <span class=md-ellipsis> OpenAI GPT-4o 完全免费 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0509-model-spec.html> <span class=md-ellipsis> OpenAI 大型语言模型规范 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0429-ai-survey.html> <span class=md-ellipsis> 2024大规模AI基础设施形势调研 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0410-cnai-wp.html> <span class=md-ellipsis> 云原生人工智能白皮书 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0408-after-kimi.html> <span class=md-ellipsis> Kimi火了后国内其他大模型 </span> </a> </li> <li class="md-nav__item md-nav__item--active"> <input class="md-nav__toggle md-toggle" id=__toc type=checkbox> <label class="md-nav__link md-nav__link--active" for=__toc> <span class=md-ellipsis> DBRX 开源 LLM 介绍 </span> <span class="md-nav__icon md-icon"></span> </label> <a class="md-nav__link md-nav__link--active" href=0407-dbrx.html> <span class=md-ellipsis> DBRX 开源 LLM 介绍 </span> </a> <nav aria-label=导航 class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 导航 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#dbrx> <span class=md-ellipsis> DBRX 是什么？ </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_1> <span class=md-ellipsis> 在基准测试中与领先的开放模型相比的质量 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_2> <span class=md-ellipsis> 在基准测试中与领先的闭源模型相比的质量 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#rag> <span class=md-ellipsis> 在长上下文任务和 RAG 上的质量 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_3> <span class=md-ellipsis> 训练效率 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_4> <span class=md-ellipsis> 推理效率 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#dbrx_1> <span class=md-ellipsis> 我们如何构建 DBRX </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#databricks-dbrx> <span class=md-ellipsis> 在 Databricks 上开始使用 DBRX </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_5> <span class=md-ellipsis> 结论 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_6> <span class=md-ellipsis> 贡献 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_7> <span class=md-ellipsis> 参考 </span> </a> </li> </ul> </nav> </li> <li class=md-nav__item> <a class=md-nav__link href=0403-cp-to-profit.html> <span class=md-ellipsis> AI 流程编排化算力为算利 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0327-transformer.html> <span class=md-ellipsis> 谁将替代 Transformer </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=0326-compute-power.html> <span class=md-ellipsis> 金融行业迎来大模型时代 </span> </a> </li> </ul> </nav> </li> <li class="md-nav__item md-nav__item--pruned md-nav__item--nested"> <a class=md-nav__link href=../../open/index.html> <span class=md-ellipsis> 智海拾贝 </span> <span class="md-nav__icon md-icon"></span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=../../contact/index.html> <span class=md-ellipsis> 联系我们 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class="md-sidebar md-sidebar--secondary" data-md-component=sidebar data-md-type=toc hidden> <div class=md-sidebar__scrollwrap> <div class=md-sidebar__inner> <nav aria-label=导航 class="md-nav md-nav--secondary"> <label class=md-nav__title for=__toc> <span class="md-nav__icon md-icon"></span> 导航 </label> <ul class=md-nav__list data-md-component=toc data-md-scrollfix> <li class=md-nav__item> <a class=md-nav__link href=#dbrx> <span class=md-ellipsis> DBRX 是什么？ </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_1> <span class=md-ellipsis> 在基准测试中与领先的开放模型相比的质量 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_2> <span class=md-ellipsis> 在基准测试中与领先的闭源模型相比的质量 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#rag> <span class=md-ellipsis> 在长上下文任务和 RAG 上的质量 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_3> <span class=md-ellipsis> 训练效率 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_4> <span class=md-ellipsis> 推理效率 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#dbrx_1> <span class=md-ellipsis> 我们如何构建 DBRX </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#databricks-dbrx> <span class=md-ellipsis> 在 Databricks 上开始使用 DBRX </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_5> <span class=md-ellipsis> 结论 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_6> <span class=md-ellipsis> 贡献 </span> </a> </li> <li class=md-nav__item> <a class=md-nav__link href=#_7> <span class=md-ellipsis> 参考 </span> </a> </li> </ul> </nav> </div> </div> </div> <div class=md-content data-md-component=content> <article class="md-content__inner md-typeset"> <a class="md-content__button md-icon" href=https://github.com/d-run/drun-docs/edit/main/docs/zh/docs/blogs/2024/0407-dbrx.md title=查看编辑历史> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13.5 8H12v5l4.28 2.54.72-1.21-3.5-2.08zM13 3a9 9 0 0 0-9 9H1l3.96 4.03L9 12H6a7 7 0 0 1 7-7 7 7 0 0 1 7 7 7 7 0 0 1-7 7c-1.93 0-3.68-.79-4.94-2.06l-1.42 1.42A8.9 8.9 0 0 0 13 21a9 9 0 0 0 9-9 9 9 0 0 0-9-9"></path></svg> </a> <a class="md-content__button md-icon" href=https://github.com/d-run/drun-docs/edit/main/docs/zh/docs/blogs/2024/0407-dbrx.md title=edit.link.title> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M10 20H6V4h7v5h5v3.1l2-2V8l-6-6H6c-1.1 0-2 .9-2 2v16c0 1.1.9 2 2 2h4zm10.2-7c.1 0 .3.1.4.2l1.3 1.3c.2.2.2.6 0 .8l-1 1-2.1-2.1 1-1c.1-.1.2-.2.4-.2m0 3.9L14.1 23H12v-2.1l6.1-6.1z"></path></svg> </a> <a class="md-content__button md-icon" href=https://github.com/d-run/drun-docs/edit/main/docs/zh/docs/blogs/2024/0407-dbrx.md title=查看源文件> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M17 18c.56 0 1 .44 1 1s-.44 1-1 1-1-.44-1-1 .44-1 1-1m0-3c-2.73 0-5.06 1.66-6 4 .94 2.34 3.27 4 6 4s5.06-1.66 6-4c-.94-2.34-3.27-4-6-4m0 6.5a2.5 2.5 0 0 1-2.5-2.5 2.5 2.5 0 0 1 2.5-2.5 2.5 2.5 0 0 1 2.5 2.5 2.5 2.5 0 0 1-2.5 2.5M9.27 20H6V4h7v5h5v4.07c.7.08 1.36.25 2 .49V8l-6-6H6a2 2 0 0 0-2 2v16a2 2 0 0 0 2 2h4.5a8.2 8.2 0 0 1-1.23-2"></path></svg> </a> <h1 id=dbrx-llm>DBRX 介绍：一款全新的、强大的开源 LLM 模型<a class=headerlink href=#dbrx-llm title="Permanent link">¶</a></h1> <blockquote> <p>转载自 <a href=https://www.databricks.com/blog/introducing-dbrx-new-state-art-open-llm>databricks</a></p> </blockquote> <p><img alt="dbrx blog header" src=../images/dbrx01.png></p> <p>今天，我们很高兴向大家介绍 DBRX，这是由 Databricks 创建的一种开放的通用 LLM。 在一系列标准基准测试中，DBRX 在已建立的开放 LLM 中树立了新的技术水平。 此外，它为开放社区和构建自己的 LLM 的企业提供了之前仅限于闭源模型 API 的功能； 根据我们的测量，它超越了 GPT-3.5，并且与 Gemini 1.0 Pro 竞争。 它是一种特别强大的代码模型，在编程方面超越了专门的 CodeLLaMA-70B 模型，除了作为通用 LLM 的优势之外。</p> <p>这种技术水平的提高伴随着训练和推理性能的显著改进。由于其细粒度的专家混合 (MoE) 架构，DBRX 在开放模型中的效率方面取得了突破性进展。 推理速度比 LLaMA2-70B 快 2 倍，而 DBRX 的总参数量和活跃参数量都只有 Grok-1 的 40%。当在 Mosaic AI Model Serving 上托管时， DBRX 可以以每个用户每秒 150 个 tok 的速度生成文本。我们的客户将发现，相比于训练相同最终模型质量的密集模型， 训练 MoE 模型的 FLOP 效率提高了约 2 倍。 从头到尾，我们的 DBRX 整体配方（包括预训练数据、模型架构和优化策略）可以在几乎 4 倍的计算资源下达到与我们上一代 MPT 模型相同的质量。</p> <p><img alt="general knowledge infographic" src=../images/dbrx02.png></p> <p>图 1：DBRX 在语言理解（MMLU）、编程（HumanEval）和数学（GSM8K）等方面超越了已建立的开源模型。</p> <p>基础模型（<a href=https://huggingface.co/databricks/dbrx-base>DBRX Base</a>） 和微调模型（<a href=https://huggingface.co/databricks/dbrx-instruct>DBRX Instruct</a>）的权重可在 Hugging Face 上以开放许可证获得。 从今天开始，DBRX 可供 Databricks 的客户通过 API 使用，并且 Databricks 的客户可以从头开始预训练自己的 DBRX 类模型， 或者使用我们的检查点之一继续训练，使用的是与我们构建模型时相同的工具和科学方法。DBRX 已经被集成到我们的 GenAI 动力产品中， 在诸如 SQL 的应用中，早期推出的版本已经超越了 GPT-3.5 Turbo，并且正在与 GPT-4 Turbo 竞争。它在 RAG 任务中也是开放模型和 GPT-3.5 Turbo 中的领先模型。</p> <p>训练混合专家模型很困难。我们不得不克服各种科学和性能挑战，以构建一个足够稳健的流水线，以便以有效的方式可重复地训练 DBRX 类模型。 现在我们已经做到了这一点，我们拥有了一个独一无二的训练堆栈，允许任何企业从头开始训练世界级的 MoE 基础模型。我们期待与我们的客户分享这种能力，并与社区分享我们的经验教训。</p> <p>从 Hugging Face（<a href=https://huggingface.co/databricks/dbrx-base>DBRX Base</a>、 <a href=https://huggingface.co/databricks/dbrx-instruct>DBRX Instruct</a>）下载 DBRX， 或在我们的 <a href=https://huggingface.co/spaces/databricks/dbrx-instruct>HF Space</a> 中尝试 DBRX Instruct，或者在 github 上查看我们的模型仓库：<a href=https://www.github.com/databricks/dbrx>databricks/dbrx</a>。</p> <h2 id=dbrx>DBRX 是什么？<a class=headerlink href=#dbrx title="Permanent link">¶</a></h2> <p>DBRX 是一种基于 transformer 的仅解码器大型语言模型（LLM），使用下一个令牌预测进行训练。它采用精细的混合专家（MoE）架构， 总共有 1320 亿参数，其中 360 亿参数在任何输入上都是活跃的。它在 12T 个文本和代码数据上进行了预训练。 与 Mixtral 和 Grok-1 等其他开放的 MoE 模型相比，DBRX 是细粒度的，意味着它使用更多数量的较小专家。 DBRX 有 16 个专家，并选择其中 4 个，而 Mixtral 和 Grok-1 有 8 个专家，并选择其中 2 个。 这提供了 65 倍更多的专家组合可能性，我们发现这可以提高模型质量。DBRX 使用旋转位置编码（RoPE）、门控线性单元（GLU）和分组查询注意力（GQA）。 它使用 GPT-4 的分词器，该分词器提供在 <a href=https://github.com/openai/tiktoken>tiktoken</a> 仓库中提供的。我们根据详尽的评估和扩展实验做出了这些选择。</p> <p>DBRX 在经过精心策划的 12T 个令牌的数据上进行了预训练，最大上下文长度为 32k 个令牌。我们估计，与用于预训练 MPT 系列模型的数据相比， 这个数据至少每个令牌更好了 2 倍。使用完整的 Databricks 工具套件，包括 Apache Spark™ 和 Databricks 笔记本进行数据处理， Unity Catalog 进行数据管理和治理，以及 MLflow 进行实验跟踪，我们开发了这个新的数据集。我们在预训练中使用了课程学习， 在训练过程中改变数据混合的方式，我们发现这样可以显著提高模型质量。</p> <h2 id=_1>在基准测试中与领先的开放模型相比的质量<a class=headerlink href=#_1 title="Permanent link">¶</a></h2> <p>表 1 展示了 DBRX Instruct 和领先的已建立的开放模型的质量。 DBRX Instruct 在复合基准测试、编程和数学基准测试以及 MMLU 方面是领先的。它在标准基准测试上超越了所有聊天或指导微调模型。</p> <p><strong>复合基准测试。</strong> 我们在两个复合基准测试上评估了 DBRX Instruct 和其他模型： <a href=https://huggingface.co/spaces/HuggingFaceH4/open_llm_leaderboard>Hugging Face Open LLM Leaderboard</a> （包括 ARC-Challenge、HellaSwag、MMLU、TruthfulQA、WinoGrande 和 GSM8k 的平均分）和 <a href=https://github.com/mosaicml/llm-foundry/blob/main/scripts/eval/local_data/EVAL_GAUNTLET.md>Databricks Model Gauntlet</a> （包括超过 30 个任务，涵盖世界知识、常识推理、语言理解、阅读理解、符号问题解决和编程六个类别）。</p> <p>在我们评估的模型中，DBRX Instruct 在两个复合基准测试中得分最高： Hugging Face Open LLM Leaderboard（74.5%，次高模型为 Mixtral Instruct 的 72.7%）和 Databricks Gauntlet（66.8%，次高模型为 Mixtral Instruct 的 60.7%）。</p> <p><strong>编程和数学。</strong> DBRX Instruct 在编程和数学方面表现特别出色。在 HumanEval（70.1%，Grok-1 的 63.2%，Mixtral Instruct 的 54.8%， LLaMA2-70B 变种中表现最佳的 32.2%）和 GSM8k（66.9%，Grok-1 的 62.9%，Mixtral Instruct 的 61.1%，LLaMA2-70B 变种中表现最佳的 54.1%）上， 它的得分高于我们评估的其他开放模型。尽管 Grok-1 的参数数量是 DBRX 的 2.4 倍，但 DBRX 在 HumanEval 上的表现优于 Grok-1， 即使 DBRX Instruct 是为通用用途设计的（Meta 在 <a href=https://ai.meta.com/blog/code-llama-large-language-model-coding/ >CodeLLaMA 博客</a> 中报告的 HumanEval 上的得分为 70.1%，超过了专门用于编程的 CodeLLaMA-70B Instruct 模型的 67.8%）。</p> <p><strong>MMLU。</strong> DBRX Instruct 在 MMLU 上的得分高于我们考虑的所有其他模型，达到了 73.7%。</p> <table> <thead> <tr> <th><strong>模型</strong></th> <th>DBRX Instruct</th> <th>Mixtral Instruct</th> <th>Mixtral Base</th> <th>LLaMA2-70B Chat</th> <th>LLaMA2-70B Base</th> <th>Grok-11</th> </tr> </thead> <tbody> <tr> <td><strong>Open LLM Leaderboard2（下面 6 行的平均值）</strong></td> <td><strong>74.5%</strong></td> <td>72.7%</td> <td>68.4%</td> <td>62.4%</td> <td>67.9%</td> <td>—</td> </tr> <tr> <td><strong>ARC-challenge 25-shot</strong></td> <td>68.9%</td> <td><strong>70.1%</strong></td> <td>66.4%</td> <td>64.6%</td> <td>67.3%</td> <td>—</td> </tr> <tr> <td><strong>HellaSwag 10-shot</strong></td> <td><strong>89.0%</strong></td> <td>87.6%</td> <td>86.5%</td> <td>85.9%</td> <td>87.3%</td> <td>—</td> </tr> <tr> <td><strong>MMLU 5-shot</strong></td> <td><strong>73.7%</strong></td> <td>71.4%</td> <td>71.9%</td> <td>63.9%</td> <td>69.8%</td> <td>73.0%</td> </tr> <tr> <td><strong>Truthful QA 0-shot</strong></td> <td><strong>66.9%</strong></td> <td>65.0%</td> <td>46.8%</td> <td>52.8%</td> <td>44.9%</td> <td>—</td> </tr> <tr> <td><strong>WinoGrande 5-shot</strong></td> <td>81.8%</td> <td>81.1%</td> <td>81.7%</td> <td>80.5%</td> <td><strong>83.7%</strong></td> <td>—</td> </tr> <tr> <td><strong>GSM8k CoT 5-shot maj@13</strong></td> <td><strong>66.9%</strong></td> <td>61.1%</td> <td>57.6%</td> <td>26.7%</td> <td>54.1%</td> <td>62.9% (8-shot)</td> </tr> <tr> <td><strong>Gauntlet v0.34（30+ 个多样任务的平均值）</strong></td> <td><strong>66.8%</strong></td> <td>60.7%</td> <td>56.8%</td> <td>52.8%</td> <td>56.4%</td> <td>—</td> </tr> <tr> <td><strong>HumanEval5 0-Shot, pass@1（编程）</strong></td> <td><strong>70.1%</strong></td> <td>54.8%</td> <td>40.2%</td> <td>32.2%</td> <td>31.0%</td> <td>63.2%</td> </tr> </tbody> </table> <p>表 1. DBRX Instruct 和领先的开放模型的质量。有关收集数字的详细信息，请参阅脚注。粗体和下划线表示最高得分。</p> <h2 id=_2>在基准测试中与领先的闭源模型相比的质量<a class=headerlink href=#_2 title="Permanent link">¶</a></h2> <p>表 2 展示了 DBRX Instruct 和领先的闭源模型的质量。根据每个模型创建者报告的得分，DBRX Instruct 超越了 GPT-3.5（如 GPT-4 论文中所述），并且与 Gemini 1.0 Pro 和 Mistral Medium 竞争。</p> <p>在我们考虑的几乎所有基准测试中，DBRX Instruct 超越或与 GPT-3.5 相匹配。DBRX Instruct 在 MMLU 方面的表现优于 GPT-3.5 （MMLU 中的总体得分为 73.7%，GPT-3.5 为 70.0%），在 HellaSwag（89.0% vs. 85.5%）和 WinoGrande（81.8% vs. 81.6%）等常识推理方面的表现也优于 GPT-3.5。 DBRX Instruct 在编程和数学推理方面的表现尤为出色，例如在 HumanEval（70.1% vs. 48.1%）和 GSM8k（72.8% vs. 57.1%）方面。 DBRX Instruct 与 Gemini 1.0 Pro 和 Mistral Medium 竞争。 DBRX Instruct 在 Inflection Corrected MTBench、MMLU、HellaSwag 和 HumanEval 上的得分高于 Gemini 1.0 Pro，而 Gemini 1.0 Pro 在 GSM8k 上更强。 DBRX Instruct 和 Mistral Medium 在 HellaSwag 上的得分相似，而 Mistral Medium 在 Winogrande 和 MMLU 上更强， DBRX Instruct 在 HumanEval、GSM8k 和 Inflection Corrected MTBench 上更强。</p> <table> <thead> <tr> <th><strong>模型</strong></th> <th>DBRX Instruct</th> <th><a href=https://arxiv.org/pdf/2303.08774.pdf>GPT-3.5</a>7</th> <th><a href=https://arxiv.org/pdf/2303.08774.pdf>GPT-4</a>8</th> <th><a href=https://www.anthropic.com/news/claude-3-family>Claude 3 Haiku</a></th> <th><a href=https://www.anthropic.com/news/claude-3-family>Claude 3 Sonnet</a></th> <th><a href=https://www.anthropic.com/news/claude-3-family>Claude 3 Opus</a></th> <th><a href=https://arxiv.org/abs/2312.11805>Gemini 1.0 Pro</a></th> <th><a href=https://arxiv.org/abs/2403.05530>Gemini 1.5 Pro</a></th> <th><a href=https://docs.mistral.ai/platform/endpoints/ >Mistral Medium</a></th> <th><a href=https://mistral.ai/news/mistral-large/ >Mistral Large</a></th> </tr> </thead> <tbody> <tr> <td><strong>MT Bench (</strong><a href=https://inflection.ai/inflection-2-5><strong>Inflection corrected</strong></a><strong>, n=5)</strong></td> <td>8.39 ± 0.08</td> <td>—</td> <td>—</td> <td>8.41 ± 0.04</td> <td>8.54 ± 0.09</td> <td>9.03 ± 0.06</td> <td>8.23 ± 0.08</td> <td>—</td> <td>8.05 ± 0.12</td> <td>8.90 ± 0.06</td> </tr> <tr> <td><strong>MMLU 5-shot</strong></td> <td>73.7%</td> <td>70.0%</td> <td>86.4%</td> <td>75.2%</td> <td>79.0%</td> <td>86.8%</td> <td>71.8%</td> <td>81.9%</td> <td>75.3%</td> <td>81.2%</td> </tr> <tr> <td><strong>HellaSwag 10-shot</strong></td> <td>89.0%</td> <td>85.5%</td> <td>95.3%</td> <td>85.9%</td> <td>89.0%</td> <td>95.4%</td> <td>84.7%</td> <td>92.5%</td> <td>88.0%</td> <td>89.2%</td> </tr> <tr> <td><strong>HumanEval 0-Shot</strong> <strong>pass@1</strong> <strong>(Programming)</strong></td> <td>70.1% temp=0, N=1</td> <td>48.1%</td> <td>67.0%</td> <td>75.9%</td> <td>73.0%</td> <td>84.9%</td> <td>67.7%</td> <td>71.9%</td> <td>38.4%</td> <td>45.1%</td> </tr> <tr> <td><strong>GSM8k CoT maj@1</strong></td> <td>72.8% (5-shot)</td> <td>57.1% (5-shot)</td> <td>92.0% (5-shot)</td> <td>88.9%</td> <td>92.3%</td> <td>95.0%</td> <td>86.5%(maj1<a class="magiclink magiclink-github magiclink-mention" href=https://github.com/32 title="GitHub User: 32">@32</a>)</td> <td>91.7% (11-shot)</td> <td><a href=https://twitter.com/IntuitMachine/status/1734189967948288464/photo/1>66.7% (5-shot)</a></td> <td>81.0% (5-shot)</td> </tr> <tr> <td><strong>WinoGrande 5-shot</strong></td> <td>81.8%</td> <td>81.6%</td> <td>87.5%</td> <td>—</td> <td>—</td> <td>—</td> <td>—</td> <td>—</td> <td>88.0%</td> <td>86.7%</td> </tr> </tbody> </table> <p>表 2. DBRX Instruct 和领先的闭源模型的质量。除 Inflection Corrected MTBench（我们在模型端点上自行测量的数据）外， 其他数字均由这些模型的创建者在各自的白皮书中报告。有关详细信息，请参阅脚注。</p> <h2 id=rag>在长上下文任务和 RAG 上的质量<a class=headerlink href=#rag title="Permanent link">¶</a></h2> <p>DBRX Instruct 在训练过程中使用了长达 32K 个令牌的上下文窗口。表 3 对其在性能上进行了与 Mixtral Instruct 和 GPT-3.5 Turbo、GPT-4 Turbo API 的最新版本在一组长上下文基准测试（来自 <a href=https://arxiv.org/abs/2307.03172>Lost in the Middle</a> 论文的 KV-Pairs 和 HotpotQAXL，这是 HotPotQA 的修改版本，将任务扩展到更长的序列长度）上的表现进行了比较。GPT-4 Turbo 通常是这些任务中最好的模型。然而，除一个例外外，DBRX Instruct 在所有上下文长度和序列的所有部分上的表现都优于 GPT-3.5 Turbo。总体而言，DBRX Instruct 和 Mixtral Instruct 的性能相似。</p> <table> <thead> <tr> <th><strong>模型</strong></th> <th>DBRX Instruct</th> <th>Mixtral Instruct</th> <th>GPT-3.5 Turbo (API)</th> <th>GPT-4 Turbo (API)</th> </tr> </thead> <tbody> <tr> <td><strong>答案在上下文的前三分之一</strong></td> <td>45.1%</td> <td>41.3%</td> <td>37.3%*</td> <td><strong>49.3</strong>%</td> </tr> <tr> <td><strong>答案在上下文的中间三分之一</strong></td> <td>45.3%</td> <td>42.7%</td> <td>37.3%*</td> <td><strong>49.0</strong>%</td> </tr> <tr> <td><strong>答案在上下文的后三分之一</strong></td> <td>48.0%</td> <td>44.4%</td> <td>37.0%*</td> <td><strong>50.9</strong>%</td> </tr> <tr> <td><strong>2K 上下文</strong></td> <td>59.1%</td> <td>64.6%</td> <td>36.3%</td> <td><strong>69.3%</strong></td> </tr> <tr> <td><strong>4K 上下文</strong></td> <td><strong>65.1</strong>%</td> <td>59.9%</td> <td>35.9%</td> <td>63.5%</td> </tr> <tr> <td><strong>8K 上下文</strong></td> <td>59.5%</td> <td>55.3%</td> <td>45.0%</td> <td><strong>61.5%</strong></td> </tr> <tr> <td><strong>16K 上下文</strong></td> <td>27.0%</td> <td>20.1%</td> <td><strong>31.7%</strong></td> <td>26.0%</td> </tr> <tr> <td><strong>32K 上下文</strong></td> <td>19.9%</td> <td>14.0%</td> <td>—</td> <td><strong>28.5%</strong></td> </tr> </tbody> </table> <p>表 3. 模型在 KV-Pairs 和 HotpotQAXL 基准测试中的平均性能。粗体是最高得分。 下划线是除 GPT-4 Turbo 外的最高得分。GPT-3.5 Turbo 支持最大上下文长度为 16K， 因此我们无法在 32K 上评估它。GPT-3.5 Turbo 的开始、中间和结尾的平均值仅包括不超过 16K 的上下文。</p> <p>使用 RAG（检索增强生成）是利用模型上下文的最受欢迎的方法之一。在 RAG 中，从数据库中检索与提示相关的内容，并将其与提示一起提供给模型，以便为模型提供比其原本拥有的更多信息。表 4 展示了 DBRX 在两个 RAG 基准测试（自然问题和 HotPotQA）上的质量，当模型还提供了从维基百科文章语料库中使用嵌入模型 bge-large-en-v1.5 检索的前 10 段内容。DBRX Instruct 与开放模型如 Mixtral Instruct 和 LLaMA2-70B Chat 以及当前版本的 GPT-3.5 Turbo 相竞争。</p> <table> <thead> <tr> <th><strong>模型</strong></th> <th>DBRX Instruct</th> <th>Mixtral Instruct</th> <th>LLaMa2-70B Chat</th> <th>GPT 3.5 Turbo (API)</th> <th>GPT 4 Turbo (API)</th> </tr> </thead> <tbody> <tr> <td><strong>自然问题</strong></td> <td>60.0%</td> <td>59.1%</td> <td>56.5%</td> <td>57.7%</td> <td><strong>63.9%</strong></td> </tr> <tr> <td><strong>HotPotQA</strong></td> <td>55.0%</td> <td>54.2%</td> <td>54.7%</td> <td>53.0%</td> <td><strong>62.9%</strong></td> </tr> </tbody> </table> <p>表 4. 在给定使用 bge-large-en-v1.5 检索的维基百科语料库的前 10 段内容的情况下，模型的性能。 准确率是通过与模型的答案匹配来衡量的。粗体是最高得分。下划线是除 GPT-4 Turbo 外的最高得分。</p> <h2 id=_3>训练效率<a class=headerlink href=#_3 title="Permanent link">¶</a></h2> <p>模型质量必须放在训练和使用的效率背景下。这在 Databricks 尤为重要，因为我们构建像 DBRX 这样的模型是为了为客户建立训练自己基础模型的流程。</p> <p>我们发现训练混合专家模型在训练效率方面提供了显著的改进（表 5）。例如，训练一个较小的 DBRX 家族成员，称为 DBRX MoE-B（23.5B 总参数，6.6B 活跃参数），在 Databricks LLM Gauntlet 上达到 45.5% 的得分所需的 FLOP 数比 LLaMA2-13B 达到 43.8% 的得分所需的 FLOP 数少 1.7 倍。DBRX MoE-B 的活跃参数数量也只有 LLaMA2-13B 的一半。</p> <p>从整体上看，我们的端到端 LLM 预训练流程在过去十个月中变得几乎更加高效。2023 年 5 月 5 日，我们发布了 <a href=https://www.databricks.com/blog/mpt-7b>MPT-7B</a>，这是一个在 1T 令牌上训练的 7B 参数模型，达到了 Databricks LLM Gauntlet 30.9% 的得分。DBRX 家族的一个成员称为 DBRX MoE-A（7.7B 总参数，2.2B 活跃参数），在 Databricks Gauntlet 上达到了 30.5% 的得分，所需的 FLOP 数比 MPT-7B 达到 30.9% 的得分少了 3.7 倍。这种效率的提高是许多改进的结果，包括使用 MoE 架构、网络的其他架构变化、更好的优化策略、更好的分词以及非常重要的是更好的预训练数据。</p> <p>独立而言，更好的预训练数据对模型质量产生了重大影响。我们使用 DBRX 预训练数据训练了一个使用 1T 令牌的 7B 模型（称为 DBRX Dense-A）。它在 Databricks Gauntlet 上达到了 39.0% 的得分，而 MPT-7B 的得分为 30.9%。我们估计，我们的新预训练数据每个令牌至少比训练 MPT-7B 的数据更好了 2 倍。换句话说，我们估计只需要一半的令牌数量就可以达到相同的模型质量。我们通过使用 500B 个令牌对 DBRX Dense-A 进行训练来确定这一点；它在 Databricks Gauntlet 上的表现优于 MPT-7B，达到了 32.1%。除了更好的数据质量之外，另一个对令牌效率的重要贡献者可能是 GPT-4 的分词器，它具有大型词汇表，并且被认为在令牌效率方面特别高效。这些关于改善数据质量的经验直接转化为我们的客户用于根据自己的数据训练基础模型的实践和工具。</p> <table> <thead> <tr> <th><strong>模型</strong></th> <th>总参数</th> <th>活跃参数</th> <th>Gauntlet 得分</th> <th>相对 FLOP</th> </tr> </thead> <tbody> <tr> <td><strong>DBRX MoE-A</strong></td> <td>7.7B</td> <td>2.2B</td> <td>30.5%</td> <td>1x</td> </tr> <tr> <td><strong>MPT-7B（1T 令牌）</strong></td> <td>—</td> <td>6.7B</td> <td>30.9%</td> <td>3.7x</td> </tr> <tr> <td><strong>DBRX Dense-A（1T 令牌）</strong></td> <td>—</td> <td>6.7B</td> <td>39.0%</td> <td>3.7x</td> </tr> <tr> <td><strong>DBRX Dense-A（500B 令牌）</strong></td> <td>—</td> <td>6.7B</td> <td>32.1%</td> <td>1.85x</td> </tr> <tr> <td><strong>DBRX MoE-B</strong></td> <td>23.5B</td> <td>6.6B</td> <td>45.5%</td> <td>1x</td> </tr> <tr> <td><strong>LLaMA2-13B</strong></td> <td>—</td> <td>13.0B</td> <td>43.8%</td> <td>1.7x</td> </tr> </tbody> </table> <p>表 5. 我们用来验证 DBRX MoE 架构和端到端训练流程的几篇测试文章的详细信息</p> <h2 id=_4>推理效率<a class=headerlink href=#_4 title="Permanent link">¶</a></h2> <p>图 2 显示了使用 NVIDIA TensorRT-LLM 在我们优化的服务基础设施和 16 位精度下为 DBRX 和类似模型提供的端到端推理效率。 我们希望这个基准尽可能接近实际使用情况，包括多个用户同时访问同一个推理服务器。 我们每秒生成一个新用户，每个用户请求包含大约 2000 个令牌的提示，并且每个响应包含 256 个令牌。</p> <p>一般来说，MoE 模型在推理方面比其总参数数量所暗示的更快。这是因为它们对每个输入使用相对较少的参数。 我们发现 DBRX 在这方面也不例外。DBRX 的推理吞吐量比一个 132B 的非 MoE 模型高 2 到 3 倍。</p> <p>推理效率和模型质量通常是相互制约的：较大的模型通常达到更高的质量，但较小的模型在推理方面更有效。 使用 MoE 架构可以实现比密集模型通常实现的更好的模型质量和推理效率的权衡。例如，DBRX 在质量上优于 LLaMA2-70B， 并且由于活跃参数数量约为一半，DBRX 的推理吞吐量比 LLaMA2-70B 快 2 倍（图 2）。 Mixtral 是 MoE 模型实现的改进 Pareto 前沿的另一个点：它比 DBRX 更小，因此在质量方面较低， 但在推理吞吐量方面更高。Databricks 基础模型 API 的用户可以在我们优化的模型服务平台上每秒看到 DBRX 达到 150 个 tok 的速度，使用 8 位量化。</p> <p><img alt="dbrx inference efficiency " src=../images/dbrx03.png></p> <p>图 2. 在我们优化的服务基础设施上使用 NVIDIA TensorRT-LLM 以 16 位精度进行各种模型配置的推理吞吐量。 模型在整个节点上以张量并行方式运行。输入提示包含大约 2000 个提示令牌，我们生成 256 个输出令牌。每秒生成一个新的用户。</p> <h2 id=dbrx_1>我们如何构建 DBRX<a class=headerlink href=#dbrx_1 title="Permanent link">¶</a></h2> <p>DBRX 是在连接了 3072 个 NVIDIA H100 的 3.2Tbps Infiniband 上进行训练的。 构建 DBRX 的主要过程 - 包括预训练、训练后处理、评估、红队测试和改进 - 在三个月的时间里进行。 这是在 Databricks 进行了几个月的科学、数据集研究和扩展实验的基础上进行的， 更不用说 Databricks 在 LLM 开发方面的多年经验，包括 MPT 和 Dolly 项目以及我们与客户一起构建和投入生产的成千上万个模型。</p> <p>为了构建 DBRX，我们利用了与我们的客户可用的相同的 Databricks 工具套件。我们使用 Unity Catalog 管理和治理我们的训练数据。我们使用新获得的 Lilac AI 探索这些数据。我们使用 Apache Spark™ 和 Databricks 笔记本来处理和清理这些数据。我们使用我们开源的训练库的优化版本训练 DBRX：MegaBlocks、LLM Foundry、Composer 和 Streaming。我们使用 Mosaic AI Training 服务在数千个 GPU 上管理大规模的模型训练和微调。我们使用 MLflow 记录我们的结果。我们通过 Mosaic AI Model Serving 和 Inference Tables 收集人类反馈，以改善质量和安全性。我们使用 Databricks Playground 手动实验模型。我们发现 Databricks 工具在各自的用途中是最好的，并且我们受益于它们都是统一产品体验的一部分。</p> <h2 id=databricks-dbrx>在 Databricks 上开始使用 DBRX<a class=headerlink href=#databricks-dbrx title="Permanent link">¶</a></h2> <p>如果您想立即开始使用 DBRX，您可以通过 Databricks Mosaic AI <a href=https://docs.databricks.com/en/machine-learning/foundation-models/index.html>Foundation Model APIs</a> 轻松使用。您可以通过我们的按需定价快速入门，并通过我们的 <a href=https://docs.databricks.com/en/large-language-models/ai-playground.html>AI Playground</a> 聊天界面查询模型。对于生产应用程序，我们提供了一个预配吞吐量选项，以提供性能保证、支持微调模型，以及额外的安全性和合规性。要私下托管 DBRX，您可以从 <a href=https://marketplace.databricks.com/details/357c33c9-7cd3-48d2-bb5b-b4a88172d193/Databricks_DBRX-Models>Databricks Marketplace</a> 下载模型，并在 <a href=https://learn.microsoft.com/en-us/azure/databricks/machine-learning/foundation-models/deploy-prov-throughput-foundation-model-apis>Model Serving</a> 上部署模型。</p> <h2 id=_5>结论<a class=headerlink href=#_5 title="Permanent link">¶</a></h2> <p>在 Databricks，我们相信每个企业都应该能够在新兴的 GenAI 世界中掌控自己的数据和命运。DBRX 是我们下一代 GenAI 产品的核心支柱，我们期待着我们的客户利用 DBRX 的能力以及我们用于构建它的工具所带来的激动人心的旅程。在过去的一年中，我们与客户一起训练了数千个 LLM。DBRX 只是 Databricks 构建的强大高效模型的一个例子，该模型适用于各种应用，从内部功能到我们的客户的雄心勃勃的用例。</p> <p>对于任何新模型来说，DBRX 的旅程只是一个开始，最好的工作将由那些在其上构建的人完成：企业和开放社区。这也只是我们在 DBRX 上的工作的开始，您应该期待更多的成果。</p> <h2 id=_6>贡献<a class=headerlink href=#_6 title="Permanent link">¶</a></h2> <p>DBRX 的开发由 <a href=https://www.databricks.com/research/mosaic>Mosaic</a> 团队领导，该团队此前构建了 MPT 模型系列，与 Databricks 的各个部门的几十位工程师、律师、采购和财务专家、项目经理、营销人员、设计师和其他贡献者合作。我们对我们的同事、朋友、家人和社区在过去几个月中的耐心和支持表示感谢。</p> <p>在创建 DBRX 时，我们站在开放和学术界的巨人的肩膀上。通过公开提供 DBRX，我们希望回馈社区，并希望我们将来能够共同构建更伟大的技术。在此背景下，我们非常感谢 <a href="https://scholar.google.com/citations?user=uMzPswkAAAAJ&hl=en">Trevor Gale</a> 及其 <a href=https://github.com/stanford-futuredata/megablocks>MegaBlocks</a> 项目的工作和合作（Trevor 的博士导师是 Databricks CTO Matei Zaharia）、<a href=https://pytorch.org/ >PyTorch</a> 团队和 <a href=https://arxiv.org/abs/2304.11277>FSDP</a> 项目、<a href=https://www.nvidia.com/ >NVIDIA</a> 和 <a href=https://github.com/NVIDIA/TensorRT-LLM>TensorRT-LLM</a> 项目、<a href=https://github.com/vllm-project/vllm>vLLM</a> 团队和项目、<a href=https://www.eleuther.ai/ >EleutherAI</a> 和他们的 <a href=https://www.eleuther.ai/projects/large-language-model-evaluation>LLM evaluation</a> 项目、<a href=http://www.lilacml.com/ >Lilac AI</a> 的 Daniel Smilkov 和 Nikhil Thorat，以及我们在 <a href=https://allenai.org/ >Allen Institute for Artificial Intelligence (AI2)</a> 的朋友们的工作和合作。</p> <h2 id=_7>参考<a class=headerlink href=#_7 title="Permanent link">¶</a></h2> <ul> <li><a href=https://huggingface.co/spaces/databricks/dbrx-instruct>在 HuggingFace 上体验 DBRX</a></li> <li><a href=https://huggingface.co/databricks/dbrx-base>在 HuggingFace 上的开放权重</a></li> <li><a href=https://github.com/databricks/dbrx>DBRX GitHub 仓库</a></li> </ul> </article> </div> <script>var target=document.getElementById(location.hash.slice(1));target&&target.name&&(target.checked=target.name.startsWith("__tabbed_"))</script> </div> <button class="md-top md-icon" data-md-component=top hidden type=button> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M13 20h-2V8l-5.5 5.5-1.42-1.42L12 4.16l7.92 7.92-1.42 1.42L13 8z"></path></svg> 回到页面顶部 </button> </main> <footer class=md-footer> <nav aria-label=页脚 class="md-footer__inner md-grid"> <a aria-label="上一页: Kimi火了后国内其他大模型" class="md-footer__link md-footer__link--prev" href=0408-after-kimi.html> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11z"></path></svg> </div> <div class=md-footer__title> <span class=md-footer__direction> 上一页 </span> <div class=md-ellipsis> Kimi火了后国内其他大模型 </div> </div> </a> <a aria-label="下一页: AI 流程编排化算力为算利" class="md-footer__link md-footer__link--next" href=0403-cp-to-profit.html> <div class=md-footer__title> <span class=md-footer__direction> 下一页 </span> <div class=md-ellipsis> AI 流程编排化算力为算利 </div> </div> <div class="md-footer__button md-icon"> <svg viewbox="0 0 24 24" xmlns=http://www.w3.org/2000/svg><path d="M4 11v2h12l-5.5 5.5 1.42 1.42L19.84 12l-7.92-7.92L10.5 5.5 16 11z"></path></svg> </div> </a> </nav> <div class="md-footer-meta md-typeset"> <div class="md-footer-meta__inner md-grid"> <div class=md-copyright> <div class=md-copyright__highlight> Copyright © 2016 - 2024 d.run </div> </div> </div> </div> </footer> </div> <div class=md-dialog data-md-component=dialog> <div class="md-dialog__inner md-typeset"></div> </div> <script id=__config type=application/json>{"base": "../..", "features": ["content.code.annotate", "content.code.copy", "content.tooltips", "navigation.tabs", "navigation.prune", "navigation.sections", "navigation.tabs.sticky", "navigation.tracking", "navigation.top", "search.highlight", "search.suggest", "search.share", "toc.follow", "navigation.path", "navigation.footer"], "search": "../../assets/javascripts/workers/search.f8cc74c7.min.js", "translations": {"clipboard.copied": "\u5df2\u590d\u5236", "clipboard.copy": "\u590d\u5236", "search.result.more.one": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.more.other": "\u5728\u8be5\u9875\u4e0a\u8fd8\u6709 # \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.none": "\u6ca1\u6709\u627e\u5230\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.one": "\u627e\u5230 1 \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.other": "# \u4e2a\u7b26\u5408\u6761\u4ef6\u7684\u7ed3\u679c", "search.result.placeholder": "\u952e\u5165\u4ee5\u5f00\u59cb\u641c\u7d22", "search.result.term.missing": "\u7f3a\u5c11", "select.version": "\u9009\u62e9\u5f53\u524d\u7248\u672c"}}</script> <script src=../../assets/javascripts/bundle.60a45f97.min.js></script> <script src=../../static/stylesheets/zoom_image.js></script> <script src=../../overrides/assets/javascripts/bundle.b97a6647.min.js></script> <script>
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?6b117ea770a78bebf27e63b402da0c4e";
      var s = document.getElementsByTagName("script")[0]; 
      s.parentNode.insertBefore(hm, s);
    })();
    </script> <script type=module>
      import mermaid from 'https://cdn.jsdelivr.net/npm/mermaid@10.2.0/+esm'
    </script> <script src="https://console.d.run/drun-copilot/chatbot-sdk.umd.js?ws=302&token=N2ZlNjFkZDItNDkyMy00Y2I1LWJlM2QtZDJlMzQ2YWM5OTE5"></script> <script>document$.subscribe(() => {
            window.update_swagger_ui_iframe_height = function (id) {
                var iFrameID = document.getElementById(id);
                if (iFrameID) {
                    full_height = (iFrameID.contentWindow.document.body.scrollHeight + 80) + "px";
                    iFrameID.height = full_height;
                    iFrameID.style.height = full_height;
                }
            }
        
            let iframe_id_list = []
            var iframes = document.getElementsByClassName("swagger-ui-iframe");
            for (var i = 0; i < iframes.length; i++) { 
                iframe_id_list.push(iframes[i].getAttribute("id"))
            }
        
            let ticking = true;
            
            document.addEventListener('scroll', function(e) {
                if (!ticking) {
                    window.requestAnimationFrame(()=> {
                        let half_vh = window.innerHeight/2;
                        for(var i = 0; i < iframe_id_list.length; i++) {
                            let element = document.getElementById(iframe_id_list[i])
                            if(element==null){
                                return
                            }
                            let diff = element.getBoundingClientRect().top
                            if(element.contentWindow.update_top_val){
                                element.contentWindow.update_top_val(half_vh - diff)
                            }
                        }
                        ticking = false;
                    });
                    ticking = true;
                }
            });
        
            const dark_scheme_name = "slate"
            
            window.scheme = document.body.getAttribute("data-md-color-scheme")
            const options = {
                attributeFilter: ['data-md-color-scheme'],
            };
            function color_scheme_callback(mutations) {
                for (let mutation of mutations) {
                    if (mutation.attributeName === "data-md-color-scheme") {
                        scheme = document.body.getAttribute("data-md-color-scheme")
                        var iframe_list = document.getElementsByClassName("swagger-ui-iframe")
                        for(var i = 0; i < iframe_list.length; i++) {
                            var ele = iframe_list.item(i);
                            if (ele) {
                                if (scheme === dark_scheme_name) {
                                    ele.contentWindow.enable_dark_mode();
                                } else {
                                    ele.contentWindow.disable_dark_mode();
                                }
                            }
                        }
                    }
                }
            }
            observer = new MutationObserver(color_scheme_callback);
            observer.observe(document.body, options);
            })</script></body> </html>